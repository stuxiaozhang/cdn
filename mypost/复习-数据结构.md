

# 数据结构

[toc]

## 问题

### 大O什么意思？

在时间复杂度中，一个算法中所有语句被重复执行的次数记为T（n）,时间复杂度用来分析T（n）的数量级，也就是算法中基本语句被执行的次数，O的含义就是表示基本语句的数量级也就是算法的数量级。

在空间复杂度中，同样用O来表示基本运算所耗费的存储空间。





### 简述数据结构的三要素

- 逻辑结构：从逻辑上描述数据，即数据之间的逻辑关系。（线性结构和非线性结构）
- 物理结构：数据在计算机内的存储方式（顺序存储，链式存储，索引存储，散列存储）
- 数据的运算：数据的运算包括数据的定义与实现，运算的定义是针对逻辑结构的，指出运算的功能；运算的实现是针对存储结构的，指出运算的具体操作步骤。





### 循环比递归效率高吗？

并不能绝对的说循环比递归效率高。

递归的优点是：代码简洁清晰，容易检查代码的正确性。缺点是：当递归调用的次数很多时，对执行效率会有一定的影响。

循环的优点是：结构简单，速度快；缺点是：并不能解决所有问题，有些问题适合用递归来解决而不适合用循环。

















### 栈和队列的区别

队列和栈都是操作受限的线性表，队列是只允许在一段插入，在另一端删除的线性表，进入队列的元素按先入先出的原则进行处理；

栈是指能在表尾进行插入和删操作的线性表，对于插入到栈的元素按先进后出的规则进行处理，插入和删除操作都在栈顶进行。





### 共享栈

利用栈底位置相对不变的特性，可以让两个顺序栈共享一个一维数组空间，将两个栈的栈底设在共享空间的两端，两个栈顶向共享空间的中间延伸，这样能够更有效的利用存储空间。





### 队列在计算机系统中的应用

队列可以用于<u>层次遍历</u>和<u>广度优先遍历</u>

1. <u>可以解决主机与外部设备之间速度不匹配的问题</u>：以打印机为例，设置一个打印数据缓冲区数据按队列存储，主机先向缓冲区中写入数据，打印机按先进先出原则一次取出数据并打印。
2. 解决多用户引起的资源竞争问题：以CPU资源的竞争为例，多个用户提出对CPU是使用请求,系统按照用户请求在时间上的先后顺序，排成队列将CPU依次分配。





### 串的存储结构

1. 定长顺序存储表示：采用一组连续的存储空间存储串的字符序列；
2. 堆分配存储表示：依然采用一组连续的存储空间存储串的字符序列，但是存储空间是在运行过程中动态分配的。





### ==KMP算法==

思想：如果已匹配相等的前缀序列中有某个后缀正好是子串的前缀，就可以将子串向后滑动到与这些后缀相匹配的位置。





### 名词解释，满二叉树，完全二叉树，二叉排序树，平衡二叉树。

- 满二叉树：高度为H，结点数为 $2^{H}-1$ 的二叉树为满二叉树。
- 完全二叉树：除最后一层外，其余各层的节点数量达到最大值，并且最后一层只能在右侧缺少节点。
- 二叉排序树：左子树上所有的关键字均小于根结点，右子树上所有关键字均大于根结点。左子树和右子树又分别是一棵二叉排序树。
- 平衡二叉树：树中每一个结点的左子树，右子树高度之差的绝对值小于等于1





### 树的存储结构

- 双亲表示法：采用一组连续的存储空间存储每个结点，同时在每个结点后面增设一个伪指针指向其双亲节点。
- 孩子表示法：将每个结点的孩子结点用单链表链接起来形成一个线性结构。
- 孩子兄弟表示法：以二叉链表作为树的存储结构，其左指针指向第一个孩子结点，右指针指向其相邻的兄弟结点。可以方便地实现树转换为二叉树的操作，易于查 找结点的孩子等，但缺点是从当前结点查找其双亲结点比较麻烦。





### 二叉树的存储结构

- 顺序存储：用一组连续的地址单元自上到下，自左到右的存储完全二叉树的结点元素。

- 链式存储：采用二叉链表来存储树的每个节点。二叉树每个结点最多两个孩子，所以设计二叉树的结点结构时考虑两个指针 指向该结点的两个孩子。

  ```c
  typedef struct BTNode()
  {
  	int data;
  	struct BTNode *lchild;
  	struct BTNode *rchild;
  }BTNode;
  ```

  



### 二叉树的遍历 

二叉树的dfs遍历，递归和非递归，一个是系统栈，一个是用户栈，为什么用户栈比系统栈效率高？

答：递归函数申请的系统栈是一个所有递归函数都要通用的栈，系统栈除了会 记录访问过的节点信息，还有其他信息比如函数参数和返回值等等，以实现函 数的递归调用。

 而用户自己定义的栈仅保存遍历所需的节点信息，是一个有针对性的设计，所 以相比之下更高效。



#### 1、先序遍历：

1）访问根结点；
2）先序遍历左子树；
3）先序遍历右子树。

  * 递归

    ```c++
    void preorder(BTBode *p)
    {
        if (p != NULL)
        {
            visit(p);
            preorder(p->lchild);
            preorder(p->rchild);
        }
    }
    ```

    

  * 非递归

    > 前序非递归遍历：
    >
    > 1. 根节点入栈
    >
    > 2. 循环栈：
    >
    >    1）根节点出栈
    >
    >    2）右节点入栈
    >
    >    3）左节点入栈

    ```c++
    void perorderNonrecursion (BTNode *bt)
    {
        if (bt != null)
        {
            BTNode * Stack[N];  // 定义一个栈
            int top = -1;  // 初始化栈
            BTNode *p;
            Stack[++ top] = p;
            if (top != -1)
            {
                p = Stack[-- top];
                visit(p);
                if (p -> rchild != null ) Stack[++ top] = p -> rchild;
                if (p -> lchild != null ) Stack[++ top] = p -> lchild;
            }
        }
    }
    ```



#### 2、中序遍历：

1）中序遍历左子树；
2）访问根结点；
3）中序遍历右子树。

  * 递归

    ```c++
    void preorder(BTBode *p)
    {
        if (p != NULL)
        {
            preorder(p->lchild);
            visit(p);
            preorder(p->rchild);
        }
    }
    ```

  * 非递归

    > 中序非递归遍历：
    >
    > 1. 根节点入栈
    >
    > 2. 循环栈：
    >
    >    1）看栈顶是否有左子，有的话，左子一直入栈
    >
    >    2）（没有左子）输出栈顶（就是“中”）
    >
    >    3）再看是否有右子，有则右子入栈，再循环2.1

    ```c++
    void inorderNonrecursion (BTNode *bt)
    {
        if (bt != null)
        {
            BTNode * Stack[N];  // 定义一个栈
            int top = -1;  // 初始化栈
            BTNode *p;
            p = bt;
            // 中序遍历
            // 栈不空 或者 指针不空 （循环条件）
            while(top != -1 || p != null)
            {
             	while(p != null)  // 左孩子存在，则左孩子入栈
                {
                    Stack[++ top] = p;
                    p = p -> lchild;
                }
                if (top != -1)  // 栈不空
                {
                    p = Stack[top --];  // 输出栈顶
                    visit(p);  // 访问元素
                    p = p -> rchild;  
                }
            }    
        }
    }
    ```

    



#### 3、后序遍历：

1）后序遍历左子树；
2）后序遍历右子树；
3）访问根结点。

  * 递归

    ```c++
    void preorder(BTBode *p)
    {
        if (p != NULL)
        {
            preorder(p->lchild);
            preorder(p->rchild);
            visit(p);
        }
    }
    ```

    

  * 非递归

    > 后序非递归遍历：
    >
    > 1. 根节点入栈
    >
    > 2. 循环栈：
    >
    >    1）看栈顶是否有左子，有的话，左子一直入栈
    >
    >    2）（没有左子）看右子
    >
    >    ​		右子入栈，再重复2.1
    >
    >    ==。。。有问题==







#### 4、层次遍历：

若树为空，则什么都不做直接返回。
否则从树的第一层开始访问，从上而下逐层遍历，在同一层中，按从左到右的顺序对结点逐个访问。

> 建立一个队列
>
> 1. 根节点入队
> 2. 出队，访问该节点：
>    - 如果有左孩子，左孩子入队
>    - 如果有右孩子，右孩子入队

```
没看懂
```





### 线索二叉树

- 二叉树的非递归遍历避免了系统栈的调用，提高了一定的效率。线索二叉树可以把用户栈也省掉，把二叉树的遍历过程线索化，进一步提高效率。

* N个结点的二叉链表，N+1个空指针域。

* 将树中的空指针域作为寻找当前结点前驱或后继的线索。

* 将二叉链表中的空指针改成指向前驱节点或后继的线索。线索链表解决了无法直接找到该结点在某种遍历序列中的前驱和后继结点的问题，解决了 二叉链表找左、右孩子困难的问题。

  * |         lchild         | ltag | data | rtag |         rchild         |
    | :--------------------: | :--: | :--: | :--: | :--------------------: |
    |  **指针**，指向左孩子  |  0   |      |  0   |  **指针**，指向右孩子  |
    | **线索**，指向前驱结点 |  1   |      |  1   | **线索**，指向后继结点 |





### 二叉树、树、森林的转换

1. 树---》二叉树：
   - 同一节点的各孩子用线连接串起来
   - 将每个结点的分支从左往右除了第一个，其余都剪掉
2. 二叉树---》树：
   - 找到一个孩子节点，然后沿着他一直往右下走
   - 途径的所有的节点都与该孩子的父节点相连；然后断开孩子之间的连线
3. 森林---》二叉树：
   - 先将森林里的每一棵树转为二叉树（树的根节点一定是没有右兄弟的，因此转换为二叉树后，根节点一定没有右孩子）
   - 再将第二棵二叉树转换为第一棵的右子树，以此类推
4. 二叉树---》森林：
   - 将根节点有右孩子的二叉树都断开
   - 再进行二叉树---》树

- 树/森林 的先序遍历 == 二叉树的先序遍历

  树/森林 的后序遍历 == 二叉树的中序遍历

![image-20200716153523309](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200716153523309.png)

> B（不懂）





### 哈夫曼树

- 权：树中的结点往往被赋予一个有意义的数值称为该结点的权。
- 结点的带权路径长度：从树的根到任意节点的路径长度与该结点的权值之积称为该结点的带权路径长度。
- 树的带权路径长度：树中所有叶结点的带权路径之和为该树的带权路径长度。
- 哈夫曼树：又叫最优二叉树。带权路径长度最小的树为哈夫曼树。





### 构造哈夫曼树的算法

- **哈夫曼树：又叫最优二叉树。带权路径长度最小的树为哈夫曼树。**
- 特点：哈夫曼树中不存在度为1的结点，权值越小的结点距离根结点的路径长度越大。

构建哈夫曼树： 

1. 将这N个结点分别作为N棵仅含一个结点的二叉树，构成森林F。
2. 构造一个新结点，并从F中选取两棵根结点权值最小的树作为新结点的左、 右子树，并且将新结点的权值置为左、右子树上根结点的权值之和。 
3. 从F中删除刚才选出的两棵树，同时将新得到的树加入F中。 
4. 重复步骤2）和3），直至F中只剩下一棵树为止。





- **哈夫曼编码：通过哈夫曼树导出的每个字符的编码，进而得到对整个字符串的编码（压缩空间）**

  哈夫曼编码是前缀码，因为根通往任意叶子节点的路径都不可能是通往其余叶子节点路径的子路径

  > 前缀码中：任意字符的编码串都不是另一字符编码串的前缀。
  >
  > 用前缀码，在解码时不会发生歧义

  - 权值：字符出现在字符串里的次数（然后构建哈夫曼树）
  - 对字符的编码：是路径






- **为什么要用哈夫曼树构建前缀码？**

  **答：**由哈夫曼树的特性可知，其树的带权路径长度是最短的。哈夫曼编码的过程中，每个字符的权值是在字符串中出现的次数，路径长度是每个字符编码的长度。字符出现的次数越多，编码长度越短。这样就使得其整个字符串在编码后的前缀码长度最短。

  <u>哈夫曼编码产生的是最短前缀码。</u>





### 图的名词解释

- 连通图：在无向图中如果两顶点之间有路径存在，就称这两个顶点是连通的。如果无向图中任意两个顶点是连通的，就称图为连通图。
- 极大连通子图（连通分量）：该连通子图包含所有的边。
  极小连通子图：在保证连通的情况边最少的子图。
- 强连通图：在有向图中，如果顶点m到顶点n有路径存在且n到m也有路径存在，就称这两个顶点是强连通的。图中任何两个顶点都是强连通的，该图就是强连通图。
- 强连通分量：有向图中的极大强连通子图为强连通分量。
- 生成树：连通图中包含所有顶点的极小连通子图。
- 网：在图中每条边都可以标上具有某个意义的数值，称为该边的权值。边上带权值得图为网，





### 图的存储方式

- **邻接矩阵法（顺序存储）（稠密图）**：用一个一维数组存储图的顶点信息，用二维数组存储各顶点的邻接关系。存储顶点邻接关系的二维数组称为邻接矩阵。
- **邻接表法（链式存储）（稀疏图）**：图中每个顶点与其有邻接关系的顶点拉成一个单链表，每个顶点都有一个单链表。
  - 十字链表法（有向图）：十字链表法是有向图的一种链式存储结构。在十字链表中，有向图中的每一条弧都有一个对应的节点，每个顶点都有对应的一个节点。
  - 邻接多重表法（无向图）





### 深度优先搜索

深度优先搜索(DFS:Depth-First-Search)：<u>深度优先搜索类似于树的先序遍历算法</u>

从起始顶点出发，先访问与其相邻的顶点，再访问与该顶点相邻且未被访问过的顶点，重复上述步骤，当与其相邻的所有顶点都被访问过，依次回退曾经访问过的顶点，若某个顶点还有与其相邻且未被访问过的顶点，则从该点开始重复上述过程，直到所有顶点均被访问过。



* 空间复杂度：**由于DFS是一个递归算法，递归是需要一个工作栈**来辅助工作，最多需要图中所有顶点进栈，所以空间复杂度为O(|V|)

* 时间复杂度：

  1. 邻接表：遍历过程的主要操作是对顶点遍历它的邻接点，由于通过访问边表来查找邻接点，所以时间复杂度为O(|E|),访问顶点时间为O(|V|),所以总的时间复杂度为O(|V|+|E|)

  2. 邻接矩阵：查找每个顶点的邻接点时间复杂度为O(|V|),对每个顶点都进行查找，所以总的时间复杂度为O(|V|2) 

  ​        

  ​        

#### 广度优先遍历

广度优先搜索(BFS:Breadth-First-Search)：<u>广度优先搜索类似于树的层序遍历算法</u>

先访问起始顶点，在访问与其相邻的所有顶点，再顺序访问与这些顶点相邻的顶点，重复上述过程，知道图中所有顶点都被访问过为止。

* 空间复杂度：**BFS需要借助一个队列**，n个顶点均需要入队一次，所以最坏情况下n个顶点在队列，那么则需要O(|V|)的空间复杂度。    
* 时间复杂度：
  1. 邻接表：每个顶点入队一次，时间复杂度为O(|V|),对于每个顶点，搜索它的邻接点，就需要访问这个顶点的所有边，所以时间复杂度为O(|E|)。所以总的时间复杂度为O(|V|+|E|)
  2. 邻接矩阵：每个顶点入队一次，时间复杂度为O(|V|),对于每个顶点，搜索它的邻接点，需要遍历一遍矩阵的一行，所以时间复杂度为O(|V|),所以总的时间复杂度为O(|V|2)





### 图的应用

![image-20200720090752462](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200720090752462.png)





### 最小生成树（普里姆算法，克鲁斯卡尔算法）

最小生成树：包含图中所有的顶点且含有最少的边且不构成回路。

普里姆算法，克鲁斯卡尔算法都是基于贪心算法策略，都是针对无向图。

### 普里姆算法（Prim算法）

**思路：**

1. 从图中任意取出一个顶点，构成一棵树
2. 然后从与这棵树相邻的边中选择最小的边，并将这条边和所连接的顶点并入树中
3. 在选择**与该树相邻**的最小边且不构成回路，将边和顶点并入
4. 重复上述过程，直到所有顶点均已并入树中。

- 双重循环，外层循环次数为n-1，内层并列的两个循环次数都是n。故普利姆算法时间复杂度为 $ O(n^2) $。而且时间复杂度只和n有关，所以适合稠密图.

![image-20200906105929961](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200906105929961.png)



> 与Dijkstra区别：Dijkstra算法是更新到起始点的距离；Prim是更新到集合S的距离





### 克鲁斯卡尔算法（Kruskal算法）

思路：

1. 将图中边按照权值从小到大排列 
2. 然后从最小的边开始枚举。如果该边并入不构成回路的话，将该边并入当前生成树。直到所有的边都检测完为止。

![image-20200906112930097](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200906112930097.png)





### 最短路径（Dijkstra算法、）

当图是带权图时，把从一个顶点到图中任意一个顶点的路径所经过的边的权值之和称为该路径的带权路径长度。把带权路径最短的那条路径称为最短路径。



### 迪杰斯特拉算法

- **单源最短路：一个源点到其余顶点的最短路径**

设有两个顶点集S和T，S中存放当前已经找到最短路径的顶点，T中存放图中剩余顶点，

1. 开始时S中只有源点，然后不断地从集合T中选取到源点的路径长度最短的顶点并入集合S中

2. 集合S每并入一个顶点，就要修改集合T中顶点到==**源点**==的最短路径长度值
3. 不断重复上述过程，直到集合T中顶点全部并入S。





### 弗洛伊德算法

* **多源汇最短路：所有顶点到所有顶点的最短路径（询问从i->j的最短路）**
  * 算法思想：
    递推产生一个n阶方阵序列A(−1)，A(0)，…，A(k)，…，A(n−1)
    其中A(k)[i][j]表示从顶点vi到顶点vj的路径长度，k表示绕行第k个顶点的运算步骤。初始时，对于任意两个顶点vi和vj，若它们之间存在边，则以此边上的权值作为它们之间的最短路径长度；若它们之间不存在有向边，则以∞作为它们之间的最短路径长度。以后逐步尝试在原路径中加入顶点k(k=0，1，…，n-1)作为中间顶点。如果增加中间顶点后，得到的路径比原来的路径长度减少了，则以此新路径代替原路径
  * 非带权图
* 两点之间经过边数最少的路径
  * 带权图
* 两点之间经过的边上权值之和最小的路径







### 拓扑排序

- **拓扑排序常用来确定一个依赖关系集中，事物发生的顺序。**

  例如，在日常工作中，可能会将项目拆分成A、B、C、D四个子部分来完成，但A依赖于B和D，C 依赖于D。为了计算这个项目进行的顺序，可对这个关系集进行拓扑排序，得出 一个线性的序列，则排在前面的任务就是需要先完成的任务。

- AOV网(Activity On Vertex)：如果我们把每个环节看成图中一个顶点，在这样一个有向图中，用顶点表示活动，用弧表示活动之间的优先关系，那么这样的有向图称为AOV网

* <u>拓扑排序就是对一个有向图构造拓扑序列的过程</u>，构造会有两种结果：
  如果此图全部顶点都被输出了，说明它是不存在回路的AOV网；
  如果没有输出全部顶点，则说明这个图存在回路，不是AOV网。

* **拓扑排序算法：**
  从AOV网中**选择一个入度为0的顶点输出，然后删去此顶点和以该顶点为起点的所有有向边**。重复这个步骤<u>直到输出图中全部顶点，或者找不到入度为0的顶点为止。</u>

* **拓扑排序流程(bfs)：**
  1. **遍历所有点找到入度为0的点，把它们入队**

  2. **开始从入度为0的点 找：**
     1. **队头出队**
     2. **遍历队头的临边**
     3. **临边的入度 - 1** 

     4. **判断此时入度是否为0：为0说明它可以做新的起点，入队**

  3. **return tt == n - 1 (队尾下标是n-1，说明所有点都已经入队)**.





### AOV网与AOE网的区别：

相同点：AOV网和AOE网都是有向无环图，<u>区别在于它们的顶点和边所代表的含义是不同的</u>：

- AOV网的顶点：活动，边：仅代表活动之间的关系，无权值。
- AOE网的顶点：事件，边：表示活动，边有权值，表示完成该活动所需要的时间。

**关键路径**：从源点到汇点的所有路径中，具有最大路径长度的路径称为关键路径，在这条路径上活动称为关键活动，完成整个工程的最短时间就是关键路径的长度。





### 查找

- 静态查找：若一个查找表的操作无需动态的修改表，称为静态查找。
- 动态查找：需要动态的插入和删除的查找表称为动态查找表。
- 平均查找长度：所有查找过程中进行关键字比较次数的平均值。





### 顺序查找

从线性表的一端开始，逐个比较关键字的值是否满足查询条件。

优点：对数据元素的存储没有要求，顺序存储或链式存储均可。
缺点：平均查找长度大，效率低。





### 折半查找

若顺序表有序，先将关键字与表中间元素比较，若相等则查找成功，否则在除中间元素以外的前半部分或后半部分进行同样的查找，如此重复直到查找成功或者确定表中没有要查找的元素，查找失败。

优点：比顺序查找效率高
缺点：查找表必须有序且必须采用顺序存储结构。





### 分块查找

将查找表分为若干个子块，块内元素可以无序，各块之间必须有序，也就是说，第一个块内最大的关键字要小于第二个块内所有记录的关键字，第二个块内最大的关键字要小于第三个块内所有记录的关键字以此类推，再建立一张索引表，表项中存放每个块的最大关键字和第一个元素的地址。
查找步骤为：

1. 在索引表中确定待查记录所在的块，可以顺序查找也可以折半查找。
2. 在块内顺序查找。

<u>吸取了顺序查找和折半查找各自的优点。</u>





### 散列表

散列函数：一个把查找表中关键字映射成为该关键字对应地址的函数。Hash(key)=Addr

散列表：根据关键字直接进行访问的散列表，建立了关键字与存储地址的直接映射关系。

散列函数的构造方法：(开除平)

1. **开放定址法**：直接取关键字的某个线性函数值为其存储地址。H(key)=a×key+b
2. **除留余数法**：假定散列表表长为m，取一个不大于m且最接近m的质数p，通过关键字取余p来得到关键字的存储地址。
3. **平方取中法**：取关键字平方的中间几位作为该关键字的存储地址。



解决冲突的办法：(线平双)

1. **开放地址法**：将产生冲突的Hash地址作为自变量，通过某种冲突解决函数得到一个新的空闲的Hash地址。

   1. <u>线性探测法</u>：冲突发生时顺序查看表中下一个单元，直到找出一个空闲单元为止。（可能会造成大量元素在相邻的散列地址上堆积，降低查找效率）

   2. <u>平方探测法</u>：设发生冲突的地址为d,平方探测法得到的新的地址序列为$(d+1)^2$，$(d-1)^2$，$(d+2)^2$，$(d-2)^2$......

      能够避免出现”堆积问题“，但是不能够探测到散列表中的所有单元。

   3. <u>双散列法</u>：使用两个散列函数，当第一个散列函数出现冲突时，就选用第二个散列函数。

2. **拉链法**：对于不同的关键字可能会通过散列函数映射到同一地址，为了避免非 同义词发生冲突，可以把所有的同义词存储在一个线性链表中，这个线性链表 由其散列地址唯一标识。拉链法适用于经常进行插入和删除的情况。



散列表的查找性能：和装填因子有关。α越大，表示装填的记录越“满”，发生冲突的可能性就越大，反之发生冲突 的可能性越小





### 排序

- 内部排序：排序期间元素全部存放在内存中。（插入，交换，选择，归并，基数）

- 外部排序：排序期间元素无法同时存放在内存中，必须在排序期间根据要求不停地在内，外存移动。（多路归并）

- 排序的稳定性：如果待排序表中有两个元素Ri、Rj，其对应的关键字keyi=keyj，且在排序前Ri在Rj前面，如果使用某一排序算法排序后，Ri仍然在Rj的前面，则称这个排序算法是稳定的，否则称排序算法是不稳定的。





### 插入排序

- **直接插入排序**：每次将一个待排序的记录按其关键字的大小插入到已排好序的子序列中。

  1. 从前面的有序子表中查出待插入元素应该插入的位置

  2. 将已排序的记录逐步向后移动，给待插入元素腾出位置，并将待插入元素复制到插入位置。 

     适用顺序存储/链式存储

- **折半插入排序**：如果是顺序存储的线性表，可以通过折半查找的方式来查找待插入元素在有序子序列的位置。确定待插入位置之后，可以统一的向后移动位置。

- **希尔排序**：将待排序列按相隔某个增量分割成若干个子序列，对各个子序列进行直接插入排序，逐渐缩小增量，重复上述步骤，直到序列基本有序，再对全体记录进行一次直接插入排序。





### 交换排序

- **冒泡排序**：从前到后（从后往前）依次两两比较相邻元素的值，若为逆序，就交换元素，每一趟排序完成之后，就有一个元素被放在最终位置上，重复上述步骤，当一趟排序不发生任何元素的交换为止。

- **快速排序**：快速排序是一种基于分治法的排序方法。 

  每一趟快排选择序列中任一个元素作为枢轴(通常选第一个元素)，将序列中比枢 轴小的元素都移到枢轴前边，比枢轴大的元素都移到枢轴后边。最后确定枢轴元素的最终位置并将枢轴放入，再对枢轴前后得到的子序列再重复上述步骤，直到每部分只有一个元素或为空为止，则所有元素放在最终位置上。

  * 时间复杂度：
    最好情况下时间复杂度为$O(nlogn)$，待排序序列越无序，算法效率越高。
    最坏情况下时间复杂度为$O(n^2)$，待排序序列越有序，算法效率越低。

  * 空间复杂度：
    由于快速排序是递归的，需要借助一个**递归工作栈**来保存每一层递归调用的必要信息，其容量应与递归调用的最大深度一致。
    最好情况下为 ⌈log2(n+1)⌉(每次partition都很均匀)递归树的深度O(logn)
    最坏情况下，因为要进行n-1次递归调用，所以栈的深度为O(n)；

  * 稳定性：快速排序是不稳定的，是因为存在交换关键字。





### 选择排序

- **简单选择排序**：每趟排序选择关键字最小的元素与序列前面的元素进行交换，每次排序均可确定一个元素的最终位置。

- **堆排序**：先将待排元素建成初始堆，以大根堆为例，堆顶元素为最大值，将其输出后，把堆底元素送入堆顶，此时堆不满足大根堆的性质，将堆顶元素向下调整（从堆的最后一个非叶子节点开始，从左到右，从下到上的顺序进行调整），成为大根堆之后再输出堆顶元素，重复上述过程，直到输出所有元素。

  * 什么是堆？

    * 堆是一棵完全二叉树，而且满足任何一个非叶结点的值都不大于(或不小于)其左右孩子结点的值。
      * 如果是每个结点的值都不小于它的左右孩子结点的值，则称为大顶堆。
      * 如果是每个结点的值都不大于它的左右孩子结点的值，则称为小顶堆。

  * 什么是堆排序？

    * 我们知道对于一个堆来说，它的根结点是整个堆中所有结点的值的最大值(大顶堆)或者最小值(小顶堆)。所以堆排序的思想就是每次将无序序列调节成一个堆，然后从堆中选择堆顶元素的值，这个值加入有序序列，无序序列减少一个，再反复调节无序序列，直到所有关键字都加入到有序序列。

    * 时间复杂度：
      堆排序的总时间可以分为①建堆部分+②n-1次向下调整堆

      堆排序的时间复杂度为O(n)+O(nlog2n)=O(nlog2n)

     * 堆排序不稳定





### 归并排序

“归并”：就是将两个或两个以上的有序表组成一个新的有序表。

归并排序是分治的思想。先将整个序列分为两半，对每一半分别进行排序，得 到两个有序序列，再将两个序列归并成一个序列即可。

>  假定待排序表含有n个记录，则可以看成是n个有序的子表，每个子表长度为1， 然后两两归并，得到 ⌈n/2⌉个长度为2或1的有序表；再两两归并，……如此重 复，直到合并成一个长度为n的有序表为止，这种排序方法称为2-路归并排序。

稳定性：稳定





![img](https://img-blog.csdnimg.cn/20190414183927348.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI1ODAwMzEx,size_16,color_FFFFFF,t_70)



可以发现，**归并排序的处理过程是由下到上的**，先处理子问题，然后再合并。而**快排正好相反，它的处理过程是由上到下的**，先分区，然后再处理子问题。**归并排序虽然是稳定的、时间复杂度为 O(nlogn) 的排序算法，但是它是非原地排序算法**。我们前面讲过，归并之所以是非原地排序算法，主要原因是**合并函数无法在原地执行**。**快速排序通过设计**巧妙的原地分区函数，**可以实现原地排序。**





### 基数排序

* 基数排序(也叫桶排序)是一种很特别的排序方法，它不是基于比较进行排序的，而是采用多关键字排序思想（即基于关键字各位的大小进行排序的），借助“分配”和“收集”两种操作对单逻辑关键字进行排序。基数排序又分为最高位优先（MSD）排序和最低位优先（LSD）排序。
* 创建0~9的十个数组，将待排序表的所有元素先按个位进行分类，将分类后的元素按索引大小取出形成新的队列，再对队列按十位，百位的顺序进行分类，重复上述过程，最后形成一个有序序列。
* 例子：53, 3, 542, 748, 14, 214, 154, 63, 616
  * 补充位数：053, 003, 542, 748, 014, 214, 154, 063, 616
  * 桶实际是一个队列，先进先出(从桶的上面进，下面出)
  * 关键字数量为n,关键字的位数为d,比如748 d=3，r为关键字的基的个数，就是组成关键字的数据的种类，比如十进制数字一共有0至9一共10个数字，即r=10
* 空间复杂度：需要开辟关键字基的个数个队列，所以空间复杂度为O(r)
* 时间复杂度：需要进行关键字位数d次"分配"和"收集"，一次"分配"需要将n个关键字放进各个队列中，一次"收集"需要将r个桶都收集一遍。所以一次"分配"和一次"收集"时间复杂度为O(n+r)。d次就需要O(d(n+r))的时间复杂度。
* 稳定性：由于是队列，先进先出的性质，所以在分配的时候是按照先后顺序分配，也就是稳定的，所以收集的时候也是保持稳定的。即基数排序是稳定的排序算法。





### 选取排序算法需要考虑的因素

1. 待排元素的数目；
2. 稳定性的要求；
3. 元素本身信息量的大小；
4. 关键字的结构及其分布情况；

若n较小，可直接采用直接插入排序或者简单选择排序。由于直接插入排序比简单选择排序移动的元素要多，所以当元素本身信息量比较大时可选用简单选择排序。
若待排序表已基本有序可以选用直接插入排序或者冒泡排序。

当n比较大时，可以选用快速排序、堆排序、归并排序。快速排序被认为是当前基于比较的内部排序中最好的排序方法，当待排序表记录随机分布时，使用快速排序速度最快。堆排序所用存储空间少于快速排序，且不会出现快速排序的最坏情况，这两种算法都是不稳定的，若要稳定排序则选用归并排序算法。





### 外部排序

采用多路归并法，包括两个相对独立的阶段：
（1）根据内部缓冲区的大小，将待排文件分成若干个大小合适的子文件，将子文件带入内存采用内部排序算法排序完成后再写回外存。
（2）对这些归并段进行逐趟归并，使归并段逐渐由小到大，直到得到整个有序文件为止。





### 提高外部排序算法的效率

由于待排文件无法全部放入内存，所以排序期间必须要频繁的进行内外存之间数据的交换，这会耗费大量的时间。所以可以通过增加归并路数来减少归并趟数，进而减少I/O次数。而增加归并路数又会增加内部排序的时间，所以引入了败者树。
增加初始归并段个数，并且不受内存空间的限制，引入了置换-选择算法。
文件经过置换-选择算法之后得到的是长度不同的初始归并段，如何组织长度不等的出使归并段的归并顺序，使得I/O次数最少，就引入了最佳归并树。





### 败者树（大的为失败者，小的为胜利者）

可视为一棵完全二叉树，每个叶结点存放各归并段在归并过程中参加比较的记录，非叶结点用来记录左右子树中的“失败者”，胜利者继续向上比较直到根节点。输出最后的胜利者。





### 置换选择算法

根据缓冲区的大小，由外存读入记录，当记录充满缓冲区时，选择最小的输出，其空缺位置由下一个记录来取代，输出记录称为当前初始归并段的一部分，如果新输出的记录比新建立归并段最大的记录小，就不能成为该归并段的一部分，只能成为下一个归并段的选择。重复上述步骤，直到缓冲区中所有记录都比当前归并段最大记录小时，就生成了一个初始归并段，用同样的方法继续生成下一个归并段，直到全部记录都处理完毕为止。





### 最佳归并树

对于K路归并算法，可用构造K叉哈夫曼树的方法来构造最佳归并树。









## 第一章：数据结构的基本概念

### 定义
* 在任何问题中，数据元素都不是孤立存在的，而是在它们之间存在着某种关系，这种数据元素相互之间的关系称为结构（Structure）。数据结构是相互之间存在一种或多种特定关系的数据元素的集合。
* 数据结构包括三方面的内容：逻辑结构、存储结构和数据的运算。数据的逻辑结构和存储结构是密不可分的两个方面，一个算法的设计取决于所选定的逻辑结构，而算法的实现依赖于所采用的存储结构。



### 逻辑结构
* 逻辑结构是指数据元素之间的逻辑关系，即从逻辑关系上描述数据。它与数据的存储无关，是独立于计算机的
* 数据的逻辑结构分为线性结构和非线性结构

![image-20200714193023951](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200714193023951.png)



### 物理结构
* 存储结构是指数据结构在计算机中的表示（又称映像），也称物理结构。它包括数据元素的表示和关系的表示。数据的存储结构是逻辑结构用计算机语言的实现，它依赖于计算机语言。数据的存储结构主要有：顺序存储、链式存储、索引存储和散列存储。
    * 顺序存储：存储的物理位置相邻。（p.s. 物理位置即信息在计算机中的位置。）
    
      * 优点：可以随机存取/顺序存取
      * 缺点：自能使用一整块相邻的存储单元，可能产生较多外部碎片
    
    * 链接存储：存储的物理位置未必相邻，通过记录相邻元素的物理位置来找到相邻元素。
    
      * 优点：不会出现碎片情况
      * 缺点：只能顺序存取；会因为指针而占用额外的存储空间
    
    * 索引存储：存储结点时，额外存储地址。形如：<关键字，地址>
    
      * 优点：检索速度快
    
      * 缺点：增加了附加的索引表，会占用更多空间
    
        ​            增删数据时也要改索引表，花更多时间
    
    * 散列存储：通过关键字直接计算出元素的物理地址。
    
      * 优点：查找，增加，删除速度快
      * 缺点：如果散列函数选的不好，会出现元素存储单元冲突，解决冲突会增加时空开销



### 算法的五个特征
* 1，有穷性：有限步之后结束
* 2，确定性：不存在二义性，即没有歧义
* 3，可行性：比如受限于计算机的计算能力，有些算法虽然理论上可行，但实际上无法完成。
* 4，输入：能被计算机处理的各种类型数据，如数字，音频，图像等等。
* 5，输出：一至多个程序输出结果。



### 算法的复杂度
* 时间复杂度：
    * 它用来衡量算法随着问题规模增大，算法执行时间增长的快慢；<u>执行算法所需的计算工作量；基本操作的执行次数</u>
    * 是问题规模的函数：T(n)是时间规模函数 时间复杂度主要分析T(n)的数量级
    * T(n)=O(f(n)) f(n)是算法中基本运算的频度（算法中语句执行次数）（O(f(n)) 表示f(n)是T(n)的某种上界）； 一般我们考虑最坏情况下的时间复杂度
* 空间复杂度：
    * 它用来衡量算法随着问题规模增大，算法所需空间的快慢；<u>执行这个算法所需要的内存空间；</u>
    * 是问题规模的函数：S(n)=O(g(n)) ；算法所需空间的增长率和g(n)的增长率相同。



### 概要: 复杂度计算为重点
* 常用的时间复杂度大小关系：$O(1) < O(log_n) < O(n) < O(nlog_n) < O(n^2) < O(n^3) $
* 复杂度如何计算
    * 时间复杂度计算（单个循环体）
        * 直接关注循环体的执行次数，设为k 
    * 时间复杂度计算（多个循环体）
        * 两个运算规则：乘法规则，加法规则



---

## 第二章：线性表

### 线性表的逻辑结构
* 定义：线性表是具有**相同数据类型**的n（n≥0）个数据元素的**有限序列**。其中n为表长。当n=0时 线性表是一个空表
* 特点：线性表中第一个元素称为表头元素；最后一个元素称为表尾元素。
除第一个元素外，每个元素有且仅有一个直接前驱。
除最后一个元素外，每个元素有且仅有一个直接后继。



### 线性表的顺序存储结构
* 线性表的顺序存储又称为顺序表。
它是用一组地址连续的存储单元（比如C语言里面的数组），依次存储线性表中的数据元素，从而使得逻辑上相邻的两个元素在物理位置上也相邻。

* 建立顺序表的三个属性: 

  1. 存储空间的起始位置（数组名data）
  2. 顺序表最大存储容量（MaxSize）
  3. 顺序表当前的长度（length）
  
  
  
  - 一维数组静态分配
  
  ```c
  typedef struct{
  	ElemType data[MaxSize];
  	int length;
  }Sqlist;
  ```
  
  - 一维数组动态分配，存储数组的空间是在程序执行过程中通过动态存储分配语句分配
  
  ```c
  typedef struct{
  	ElemType *data;  // 动态分配数组的指针
  	int length, MaxSize;
  }Sqlist;
  
  L.data = (ElemType *)malloc(sizeof(ElemType) * initSize);
  ```
  
  
  
* 总结：
    1. 顺序表最主要的特点是**随机访问**（C语言中基于数组），即通过首地址和元素序号可以在$O(1)$的时间内找到指定的元素。
    2. **顺序表的存储密度高**，每个结点只存储数据元素。无需给表中元素花费空间建立它们之间的逻辑关系（因为物理位置相邻特性决定）
    3. 顺序表逻辑上相邻的元素物理上也相邻，所以**插入和删除操作需要移动大量元素**。



### 顺序表的操作
1.**插入**

* 代码

    ```C
    Sqlist L;
    
    bool insertElem(Sqlist &L, int p, int e)  // 位置p插入新元素e
    {
    	if(p < 0 || p > L.length || L.length >= maxSize) return false;
        for (int i = L.length -1; i >= p; i -- )
            L.data[i + 1] = L.data[i];  // 从后向前到第i个位置，分别将这些元素都向后移动一位
        
        L.data[p] = e;  // 将该元素插入位置i 
        L.length ++ ;  // 并修改表长
        return true;
    }
    ```

* 分析：
    * 最好情况：在表尾插入（即i=n+1），元素后移语句将不执行，时间复杂度为O(1)。
    * 最坏情况：在表头插入（即i=1），元素后移语句将执行n次，时间复杂度为O(n)。
* 平均情况：在长度为n的线性表中插入一个结点时所需移动结点的平均次数为 **$O( n)$**



2.**删除**

* 算法思路：
    * 1.判断i的值是否正确
    * 2.取删除的元素
    * 3.将被删元素后面的所有元素都依次向前移动一位
    * 4.修改表长
    
* 代码

    ```c
    Sqlist L;
    
    // 位置p元素删掉，并将被删除元素赋值给e
    bool deleteElem(Sqlist &L, int p, int e)  
    {
    	if(p < 0 || p > L.length - 1) return false;
        e = L.data[i];
        for (int i = L.length -1; i >= p; i -- )
            L.data[i] = L.data[i + 1];  
        
        L.length -- ;  // 并修改表长
        return true;
    }
    ```

    

* 分析
    * 最好情况：删除表尾元素（即i=n），无须移动元素，时间复杂度为O(1)。
    * 最坏情况：删除表头元素（即i=1），需要移动除第一个元素外的所有元素，时间复杂度为O(n)。
    * 平均情况：在长度为n的线性表中删除一个结点时所需移动结点的平均次数为 **$O( n)$**



### 线性表的链式存储结构
* 线性表的链式存储是指通过一组任意的存储单元来存储线性表中的数据元素。

    ```c
    typedef struct LNode{
    	ElemType data;
    	struct LNode *next;
    }LNode, *LinkList;
    ```

* **头结点和头指针的区别？**
  
    * 头指针：头指针始终指向链表的第一个结点（无论是否有头结点）（链表必要元素）
    * 头结点：在单链表第一个元素结点前附加一个空结点（结点内通常不存储信息；数据域：可以不记录信息，也可以记录表长等信息；指针域：指向单链表的第一个元素结点）
    
* **为什么要设置头结点？**
  
    * **1.处理操作起来方便** 例如：对在第一元素结点前插入结点和删除第一结点起操作与其它结点的操作就统一了
    * **2.无论链表是否为空，其头指针是指向头结点的非空指针，因此空表和非空表的处理也就统一了。**
    
    |                    | 无头结点          | 有头节点          |
    | :----------------: | ----------------- | ----------------- |
    |  空表（判断表空）  | `p == null`       | `p->next == null` |
    | 非空表（判断表尾） | `p->next == null` | `p->next == null` |



### 单链表的操作
1. **头插法建立单链表：**

- 读入数据的顺序与链表中元素的顺序**相反**

* 建立新的结点分配内存空间，将新结点插入到当前链表的表头（即头结点之后）

```
s -> data = a[i];
-----------------------------
s -> next = c -> next;
c -> next = s;
```

- 代码

```c
void createlistFront(LNode *&C, int a[], int n)
{
	LNode *s;
    c = (LNode*) malloc(sizeof(LNode));
    c -> next = NULL;
    
    for (int i = 0; i < n; i ++ )
    {
        s = (LNode*) malloc(sizeof(LNode));
        s -> data = a[i];
        
        // 头插法的关键
        c -> next = s -> next;
        c -> next = s;
    }
}
```



2. **尾插法建立单链表：**

- 读入数据的顺序与链表中元素的顺序**相同**

* 建立新的结点分配内存空间，将新结点插入到当前链表的表尾（需要增设表为指针r，使其始终指向表尾结点）

```c
s -> data = a[i];
-----------------------------
r -> next = s;
r = r -> next;
```

* 代码

```c
LinkList create_LinkList(int n[], int length){
    LinkList L = NULL;

    LNode *s, *r = L;

    for (int i = 0; i < length; i++){
        s = (LNode *) malloc(sizeof(LNode));
        s->data = n[i];
        
        if(L == NULL) L = s;
        else r->next = s;
        r = s;
    }

    if(r != NULL) r->next = NULL; // 数组a中所有的元素都已经装入链表c中，c的终端结点的指针域置为null
    return L;
}
```



3. **按序号查找结点**

* 在单链表中从第一个结点出发，顺指针next域逐个往下搜索，直到找到第i个结点为止,否则返回最后一个结点指针域NULL。

```c
// 取出单链表L（带头结点）中第i个位置的结点指针
LNode *getElem(LinkList L,int i)
{
	LNode *p = L;
    int j = 0;

    while(p->next != NULL && j < i){
        p = p->next;
        j++;
    }

    if(j == i) return p;
    else return NULL;
}
```



4. **按值查找结点**

* 从单链表第一个结点开始，由前往后依次比较表中各结点数据域的值，若某结点数据域的值等于给定值e，则返回该结点的指针；若整个单链表中没有这样的结点，则返回NULL。

```c
LNode *locateElem(LinkList L, ElemType e)
{
    LNode *p = L -> next;
    
    while(p != NULL && p -> data != e) 
        p = p -> next;
    
    return p;
}
```



5. **插入**

* 插入操作是将值为x的新结点插入到单链表的第i个位置上。先检查插入位置的合法性，然后找到待插入位置的前驱结点，即第i−1个结点，再在其后插入新结点。

```c
// 在L的第i个位置上插入值为x的结点
void insertNode(LinkList L, int i, ElemType x)
{
    if (i < 1 || i > L.length ) return ;
    // 创建一个新结点并赋值
	LNode *s = (LNode*) malloc(sizeof(LNode));
    s -> data = x;
    
    // 找到待插入位置的前驱结点，即第i−1个结点
    LNode p = getElem(L, i - 1);
    // 再在其后插入新结点
    s - > next = p -> next;
    p -> next = s;
}
```



6. **删除**

* 删除操作是将单链表的第i个结点删除。先检查删除位置的合法性，然后查找表中第i−1个结点，即被删结点的前驱结点，再将其删除。

```c
// 删除第i个节点，并将数据域通过e返回，成功true
bool deleteNode(LinkList L, int i, ElemType &e)
{
    if (i < 1 || i > L.length ) return ;
    
    LinkNode *p, *q;
    
    p = getElem(L, i - 1);
    q = p -> next;
    
    p -> next = q -> next;
    
    e = q -> data;
    free(q);  // 调用free函数释放q所指的结点的内存空间
    
    return true;
}
```



### 双链表
* 双链表是的可以通过某节点访问它的直接前驱和后继

1. **插入**：

```c
s -> next = p -> next;
s -> prior = p;
p -> next -> prior = s;
p -> next = s;
```



2. **删除：**

```
p -> next = q -> next;
q -> next -> prior = p;
free(q);
```



### 循环链表&&静态链表
**循环链表**

* 循环单链表：循环单链表和单链表的区别在于，**表中最后一个结点的指针不是NULL，而改为指向头结点，从而整个链表形成一个环**
* 循环双链表：类比循环单链表，循环双链表链表区别于双链表就是首尾结点构成环
    * 当循环双链表为空表时，其头结点的prior域和next域都等于Head。
* 注：尾结点的next指向的是头节点

**静态链表**

* 静态链表：静态链表是用数组来描述线性表的链式存储结构。
    * 数组第一个元素不存储数据，它的指针域存储第一个元素所在的数组下标。链表最后一个元素的指针域值为-1。
    * 插删不需要移动元素，只需要修改指针

```c
typedef struct
{
	ElemType data;
	int next;
}SLinkList[MaxSize];
```



### 顺序表、链表总结

|                  | 顺序表                       | 链表                               |
| ---------------- | ---------------------------- | ---------------------------------- |
| 存取方式         | 顺序存取（随机访问）         | 顺序存取                           |
| 逻辑\物理结构    | 顺序存储：逻辑相邻，物理相邻 | 链式存储：逻辑相邻，物理不一定相邻 |
| 查找（按值查找） | $O(n )$ / $O (logn)$         | $O(n)$                             |
| （按序查找）     | $O(1 ) $                     | $O (n) $                           |
| 插入删除         | $O(n) $                      | $O(1 )$                            |
| 存储密度         | 存储密度大                   | 存储密度大（需额外存储信息）       |



-----

## 第三章：栈和队列
### 栈
* 栈（Stack）：只允许在一端进行插入或删除操作的线性表。
* 栈顶（Top）：线性表允许进行插入和删除的那一端。
* 栈底（Bottom）：固定的，不允许进行插入和删除的另一端
* 特点：
1.栈是受限的线性表，所以自然具有线性关系。
2.栈中元素后进去的必然先出来，即后进先出**LIFO**（Last In First Out）

**顺序栈**

* 栈是线性表的特例，那栈的顺序存储也是线性表顺序存储的简化。栈的顺序存储结构也叫作顺序栈。
* 顺序栈的缺点：顺序栈的存储空间大小需要事先开辟好，万一不够用就需要扩容，麻烦。很多时候对每个栈各自单独开辟存储空间的利用率不如将各个栈的存储空间共享（于是就有了共享栈）。

**共享栈**

* 共享栈：栈的栈底是相对不变的，栈顶是在变化的。将两个栈的栈底分别设在一维数组的两端。栈顶向共享空间的中间延伸
* 共享栈更有效地利用了存储空间，只有共享空间满了才会上溢，存取效率仍然是$O (1 )$

**链式栈**

* 栈是线性表的特例，线性表的存储结构还有链式存储结构，所以也可以用链表的方式来实现栈。栈的链式存储结构也叫作链栈。
* 链栈便于多个栈共享存储空间；一般不存在栈满的情况；插删节点方便。
  



### 队列

* 队列是只允许在一端进行插入，而在另一端进行删除的线性表
* 队头（Front）：允许删除的一端，又称为队首。
* 队尾（Rear）： 允许插入的一端。
* 先进入队列的元素必然先离开队列，即先进先出（First In First Out）**FIFO**

**顺序队列**

* 用数组来实现队列，可以将队首放在数组下标为0的位置。

**循环队列**

* 把数组“掰弯”，形成一个**环**。Rear指针到了下标为4的位置还能继续指回到下标为0的地方。这样首尾相连的顺序存储的队列就叫循环队列
* 入队：`rear=(rear+1)%MaxSize`
* 出队：`front=(front+1)%MaxSize`
* 概要: 那如何分辨队列是空还是满呢？
    * 方法一：**设置标志位flag**，当flag=0且rear等于front时为队列空，当flag=1且rear等于front时为队列满。
    * 方法二：我们**把front=rear仅作为队空的判定条件**。**当队列满的时候，令数组中仍然保留一个空余单元。我们认为这种情况就是队列满了。**

**链式队列**

* 队列的链式存储结构，其实就是线性表的单链表，只不过需要加点限制，只能表尾插入元素，表头删除元素。
* 为了方便操作，我们分别设置队头指针和队尾指针，队头指针指向头结点，队尾指针指向尾结点

    - 1.入队：我们知道队列只能从队尾插入元素，队头删除元素。于是入队就是在队尾指针进行插入结点操作。链队的插入操作和单链表的插入操作是一致的。

    * 2.出队：出队就是头结点的后继结点出队，然后将头结点的后继改为它后面的结点。

**双端队列**

* 双端队列是指允许两端都可以进行入队和出队操作的队列





### 栈的应用

1、括号匹配：假设有两种括号，一种圆的()，一种方的[]，嵌套的顺序是任意的。

* 算法思想：若是左括号，入栈；若是右括号，出栈一个左括号判断是否与之匹配；检验到字符串尾，还要检查栈是否为空。只有栈空，整个字符串才是括号匹配的。


![image-20200725183837532](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200725183837532.png)



2、后缀表达式求值：

* 规则：从左到右扫描表达式的每个数字和符号，遇到数字就进栈，遇到符号就将处于栈顶的两个数字出栈然后跟这个符号进行运算，最后将运算结果进栈，直到最终获得结果。

![image-20200725184547337](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200725184547337.png)



3、递归：

* 如果在一个函数、过程或数据结构的定义中又应用了它自身，那么这个函数、过程或数据结构称为是递归定义的，简称递归。递归最重要的是递归式和递归边界。
* 1.阶乘
    * 时间复杂度：O(NlogN)
* 2.斐波那契数列
    * 时间复杂度   O(2^n)

**倒序输出单链表**

```
List Reverse( List L )
{
    List p, q;
    p = L;
    L = NULL;

    while(p)
    {
        q = p;
        p = q -> Next;
        q -> Next = L;
        L = q; 
    }
    return L;
}
```





4、概要: 如何将中缀表达式转换成后缀表达式？

* 栈\树





## 队列的应用

1、队列在层序遍历的应用

2、队列在计算机系统中的应用

- 解决主机与外设速度不匹配的问题：做一个缓冲区
- 解决多用户引起的资源竞争问题







------

## 第四章 数组、矩阵、广义表













----

## 第五章 串



















---

## 第五章 树

### 树的基本概念
* 树是递归定义的结构，唯一的根和若干棵互不相交的子树/
* 结点
    * 根节点：树只有一个根结点
    * 结点的度：结点拥有的子树的数量
        * 度为0：叶子结点或者终端结点
        * 度不为0：分支结点或者非终端结点
            * 分支结点除去根结点也称为内部结点
* 树的度：树中所有结点的度数的最大值
* 结点关系
    * 祖先结点
        * 根结点到该结点的唯一路径的任意结点
    * 子孙结点
    * 双亲结点
        * 根结点到该结点的唯一路径上最接近该结点的结点
    * 孩子结点
    * 兄弟结点
        * 有相同双亲结点的结点
* 层次，高度，深度，树的高度
    * 层次：根为第一层，它的孩子为第二层，以此类推
    * 结点的深度：根结点开始自顶向下累加
    * 结点的高度：叶节点开始自底向上累加
    * 树的高度（深度）：树中结点的最大层数
* 树的性质
  
    1. 树中的结点数等于所有结点的度数加1。
    
       证明：不难想象，除根结点以外，每个结点有且仅有一个指向它的前驱结点。也就是说每个结点和指向它的分支一一对应。
       假设树中一共有b个分支，那么除了根结点，整个树就包含有b个结点，所以整个树的结点数就是这b个结点加上根结点，设为n，则n=b+1。而分支数b也就是所有结点的度数，证毕。
    
    
    2. 度为m的树中第i层上至多有m^(i−1)个结点（i≥1）。
    
       证明：（数学归纳法）
       首先考虑i=1的情况：第一层只有根结点，即一个结点，i=1带入式子满足。
       假设第i-1层满足这个性质，第i-1层最多有m i-2个结点。
       ……… ..........
       i-1层
       ………
         又因为树的度为m,所以对于第i-1层的每个结点，最多
         有m个孩子结点。所以第i层的结点数最多是i-1层的m
         倍，所以第i层上最多有m ^(i-1)个结点。
    
      3. 高度为h的m叉树至多有$(m^h-1)/(m-1)$个结点
    
      4. 具有n个结点的m叉树的最小高度为logm(n(m-1)+1) 



### 树的存储结构

* 顺序存储结构
  
    * 双亲表示法：用一组连续的存储空间存储树的结点，同时在每个结点中，用一个变量存储该结点的双亲结点在数组中的位置。
    
      该存储结构利用了每个结点（根结点除外）只有唯一双亲的性质，可以很快得到每个结点的 双亲结点，但求结点的孩子时需要遍历整个结构。
    
    ![image-20200716140457224](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200716140457224.png)
* 链式存储结构
    * 孩子表示法：把每个结点的孩子结点排列起来存储成一个单链表。所以n个结点就有n个链表；
如果是叶子结点，那这个结点的孩子单链表就是空的；
然后n个单链表的的头指针又存储在一个顺序表（数组）中。

    <img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200716141210597.png" alt="image-20200716141210597" style="zoom:80%;" />

    * 孩子兄弟表示法：又称二叉树表示法，即以二叉链表作为树的存储结构。孩子兄弟表示法使每 个结点包括三部分内容：结点值、指向结点第一个孩子结点的指针，及指向结点下一个兄弟结点 的指针（沿此域可以找到结点的所有兄弟结点）
    
      <img src="C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200716141543731.png" alt="image-20200716141543731" style="zoom:80%;" />
    
      这种存储表示法比较灵活，其最大的优点是可以<u>方便地实现树转换为二叉树的操作</u>，易于查找结点的孩子等，但缺点是从当前结点查找其双亲结点比较麻烦。若为每个结点增设一个parent 域指向其父结点，则查找结点的父结点也很方便。



### 二叉树

* 定义
  

二叉树是n（n≥0）个结点的有限集合：或者为空二叉树，即n=0。或者由一个根结点和两个互不相交的被称为根的左子树和右子树组成。左子树和右子树又分别是一棵二叉树。 

1.每个结点最多有两棵子树。
2.左右子树有顺序



* 二叉树的五种基本形态： 空树；只有一个根结点；根结点只有左子树；根结点只有右子树；根结点既有左子树又有右子树
* 特殊二叉树：斜树；满二叉树；完全二叉树
* 二叉树的性质
    * 1.非空二叉树上叶子结点数等于度为2的结点数加1
    * 2.非空二叉树上第K层上至多有 $2^k−1$ 个结点（K≥1）
    * 3.高度为H的二叉树至多有 2^H-1 个结点（H≥1）
    * 4.具有N个（N>0）结点的完全二叉树的高度为 [log2(N+1)]或[log2N] +1。



### 二叉树的存储结构
* 顺序存储
  
    * 二叉树的顺序存储结构就是用一组地址连续的存储单元依次自上而下、自左至右存储完全二叉树上的结点元素。
* 链式存储
  
    * 二叉树每个结点最多两个孩子，所以设计二叉树的结点结构时考虑两个指针指向该结点的两个孩子。
    
      ```c++
      typedef struct BTNode()
      {
      	int data;
      	struct BTNode *lchild;
      	struct BTNode *rchild;
      }BTNode;
      ```
    
      

### 二叉树的遍历

- 二叉树的dfs遍历，递归和非递归，一个是系统栈，一个是用户栈，为什么用户栈比系统栈效率高？

  答：递归函数申请的系统栈是一个所有递归函数都要通用的栈，系统栈除了会记录访问过的节点信息，还有其他信息比如函数参数和返回值等等，以实现函数的递归调用。

  而用户自己定义的栈仅保存遍历苏旭的节点信息，是一个有针对性的设计，所以相比之下更高效。



#### 1、先序遍历：

1）访问根结点；
2）先序遍历左子树；
3）先序遍历右子树。

  * 递归

    ```c++
    void preorder(BTBode *p)
    {
        if (p != NULL)
        {
            visit(p);
            preorder(p->lchild);
            preorder(p->rchild);
        }
    }
    ```

    

  * 非递归

    > 前序非递归遍历：
    >
    > 1. 根节点入栈
    >
    > 2. 循环栈：
    >
    >    1）根节点出栈
    >
    >    2）右节点入栈
    >
    >    3）左节点入栈

    ```c++
    void perorderNonrecursion (BTNode *bt)
    {
        if (bt != null)
        {
            BTNode * Stack[N];  // 定义一个栈
            int top = -1;  // 初始化栈
            BTNode *p;
            Stack[++ top] = p;
            if (top != -1)
            {
                p = Stack[-- top];
                visit(p);
                if (p -> rchild != null ) Stack[++ top] = p -> rchild;
                if (p -> lchild != null ) Stack[++ top] = p -> lchild;
            }
        }
    }
    ```



#### 2、中序遍历：

1）中序遍历左子树；
2）访问根结点；
3）中序遍历右子树。

  * 递归

    ```c++
    void preorder(BTBode *p)
    {
        if (p != NULL)
        {
            preorder(p->lchild);
            visit(p);
            preorder(p->rchild);
        }
    }
    ```

  * 非递归

    > 中序非递归遍历：
    >
    > 1. 根节点入栈
    >
    > 2. 循环栈：
    >
    >    1）看栈顶是否有左子，有的话，左子一直入栈
    >
    >    2）（没有左子）输出栈顶（就是“中”）
    >
    >    3）再看是否有右子，有则右子入栈，再循环2.1

    ```c++
    void inorderNonrecursion (BTNode *bt)
    {
        if (bt != null)
        {
            BTNode * Stack[N];  // 定义一个栈
            int top = -1;  // 初始化栈
            BTNode *p;
            p = bt;
            // 中序遍历
            // 栈不空 或者 指针不空 （循环条件）
            while(top != -1 || p != null)
            {
             	while(p != null)  // 左孩子存在，则左孩子入栈
                {
                    Stack[++ top] = p;
                    p = p -> lchild;
                }
                if (top != -1)  // 栈不空
                {
                    p = Stack[top --];  // 输出栈顶
                    visit(p);  // 访问元素
                    p = p -> rchild;  
                }
            }    
        }
    }
    ```

    



#### 3、后序遍历：

1）后序遍历左子树；
2）后序遍历右子树；
3）访问根结点。

  * 递归

    ```c++
    void preorder(BTBode *p)
    {
        if (p != NULL)
        {
            preorder(p->lchild);
            preorder(p->rchild);
            visit(p);
        }
    }
    ```

    

  * 非递归

    > 后序非递归遍历：
    >
    > 1. 根节点入栈
    >
    > 2. 循环栈：
    >
    >    1）看栈顶是否有左子，有的话，左子一直入栈
    >
    >    2）（没有左子）看右子
    >
    >    ​		右子入栈，再重复2.1
    >
    >    ==。。。有问题==







#### 4、层次遍历：

若树为空，则什么都不做直接返回。
否则从树的第一层开始访问，从上而下逐层遍历，在同一层中，按从左到右的顺序对结点逐个访问。

> 建立一个队列
>
> 1. 根节点入队
> 2. 出队，访问该节点：
>    - 如果有左孩子，左孩子入队
>    - 如果有右孩子，右孩子入队

```
没看懂
```





### 线索二叉树

- 二叉树的非递归遍历避免了系统栈的调用，提高了一定的效率。线索二叉树可以把用户栈也省掉，把二叉树的遍历过程线索化，进一步提高效率。

* N个结点的二叉链表，N+1个空指针域。

* 将树中的空指针域作为寻找当前结点前驱或后继的线索。
  
    * |         lchild         | ltag | data | rtag |         rchild         |
        | :--------------------: | :--: | :--: | :--: | :--------------------: |
        |  **指针**，指向左孩子  |  0   |      |  0   |  **指针**，指向右孩子  |
        | **线索**，指向前驱结点 |  1   |      |  1   | **线索**，指向后继结点 |

```c++
// 线索二叉树的结点定义
typedef struct TBTNode
{
    int data;
    int ltag, rtag;
    struct TBTNode *lchild;
    struct TBTNode *rchild;
}TBTNode;

// 中序遍历线索二叉树的递归过程
void InThread(TBTNode *p, TBTNode *pre)
{
    // 递归左子树线索化
    InThread(p -> lchild, pre);
    
    // 一对线索的连接，pre是p的前驱，p是pre的后继
    if (p -> lchild == null)
    {
        p -> lchild = pre;
        p -> ltag = 1;
    } 
    if (pre != null && pre -> rchild != null )
    {
        pre -> rchild = p;
        pre -> rtag = 1;
    }
    
	pre = p;
    // 递归右子树
    InThread(p -> rchild, pre);
}

// 通过中序遍历建立中序线索二叉树
void createInThread(TBTNode *root)
{
    TBTNode *pre = null;
    if (root != null)
    {
        InThread(root, pre);
        pre -> rchild = null;  // 非空二叉树，线索化
        pre -> rtag = 1;   // 后处理中序最后一个结点
    }
}
```





### 二叉树、树、森林的转换

1. 树---》二叉树：
   - 同一节点的各孩子用线连接串起来
   - 将每个结点的分支从左往右除了第一个，其余都剪掉
2. 二叉树---》树：
   - 找到一个孩子节点，然后沿着他一直往右下走
   - 途径的所有的节点都与该孩子的父节点相连；然后断开孩子之间的连线
3. 森林---》二叉树：
   - 先将森林里的每一棵树转为二叉树（树的根节点一定是没有右兄弟的，因此转换为二叉树后，根节点一定没有右孩子）
   - 再将第二棵二叉树转换为第一棵的右子树，以此类推
4. 二叉树---》森林：
   - 将根节点有右孩子的二叉树都断开
   - 再进行二叉树---》树

- 树/森林 的先序遍历 == 二叉树的先序遍历

  树/森林 的后序遍历 == 二叉树的中序遍历

![image-20200716153523309](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200716153523309.png)

> B（不懂）





### 哈夫曼树和哈夫曼编码

- **哈夫曼树：又叫最优二叉树。带权路径长度最短。**

  构建哈夫曼树：

  1. 将这N个结点分别作为N棵仅含一个结点的二叉树，构成森林F。
  2. 构造一个新结点，并从F中选取两棵根结点权值最小的树作为新结点的左、右子树，并且将新结点的权值置为左、右子树上根结点的权值之和。
  3. 从F中删除刚才选出的两棵树，同时将新得到的树加入F中。
  4. 重复步骤2）和3），直至F中只剩下一棵树为止。

  

- **哈夫曼编码：通过哈夫曼树导出的每个字符的编码，进而得到对整个字符串的编码（压缩空间）**

  哈夫曼编码是前缀码，因为根通往任意叶子节点的路径都不可能是通往其余叶子节点路径的子路径

  > 前缀码中：任意字符的编码串都不是另一字符编码串的前缀。
  >
  > 用前缀码，在解码时不会发生歧义

  - 权值：字符出现在字符串里的次数（然后构建哈夫曼树）
  - 对字符的编码：是路径

- **为什么要用哈夫曼树构建前缀码？**

  **答：**由哈夫曼树的特性可知，其树的带权路径长度是最短的。哈夫曼编码的过程中，每个字符的权值是在字符串中出现的次数，路径长度是每个字符编码的长度。字符出现的次数越多，编码长度越短。这样就使得其整个字符串在编码后的前缀码长度最短。

  哈夫曼编码产生的是最短前缀码。







---

## 第五章：图
### 图的基本概念

  * 图G由顶点集V和边集E组成，记为G=(V，E)
      * V(G)表示图G中顶点的有限非空集。用|V|表示图G中顶点的个数，也称为图G的阶
* E(G)表示图G中顶点之间的关系（边）集合。用|E|表示图G中边的条数。
* **连通图：图中任意两个顶点都是连通的**
* <u>连通分量：无向图中的极大连通子图</u>
    * **连通:顶点A到顶点B有路径**
    * 极大
        * 1.顶点足够多
        * 2.极大连通子图包含这些依附这些顶点的所有边
    * 结论1:如果一个图有n个顶点，并且有小于n-1条边，则此图必是非连通图。
    * 概要: 找连通分量的方法：
    从选取一个顶点开始，以这个顶点作为一个子图，然后逐个添加与这个子图相连的顶点和边直到所有相连的顶点都加入该子图
* 强连通：顶点V到顶点W和顶点W到顶点V都有路径
* 强连通图：图中任一对顶点都是强连通的
* 连通图的生成树：包含图中全部n个顶点，但是只有n-1条边的极小连通子图
    * 结论2:生成树去掉一条边则变成非连通图，加上一条边就会形成回路。
* 度：以该顶点为一个端点的边数目
    * 无向图中顶点V的度是指依附于该顶点的边的条数，记为TD(v)
    * 有向图中顶点V的度分为出度和入度
        * 入度（ID）是以顶点v为终点的有向边的数目
        * 出度（OD）是以顶点V为起点的有向边的数目
* 简单路径和简单回路：顶点不重复出现的路径称为简单路径。对于回路，除了第一个和最后一个顶点其余顶点不重复出现的回路称为简单回路
* 权和网：图中每条边考研赋予一定意义的数值，这个数值叫做这条边的权，有权值得图称为带权图，也叫做网
* 路径和路径长度：顶点p到q之间的路径是指顶点序列怕保存的，p,a,b,c,d,……q。路径上边的数目就是路径长度
* 回路（环）：第一个和最后一个顶点相同的路径称为回路或者环
* 距离：从顶点u到v的最短路径长度。不存在路径则为无穷



### 图的存储结构
* **邻接矩阵（顺序存储）**（稠密图） 
* **邻接表（链式存储）**（稀疏图）
    * 十字链表（有向图）
    * 邻接多重表（无向图）



### 图的遍历
#### 深度优先遍历

* 深度优先搜索(DFS:Depth-First-Search)：深度优先搜索类似于树的先序遍历算法
    * 空间复杂度：**由于DFS是一个递归算法，递归是需要一个工作栈**来辅助工作，最多需要图中所有顶点进栈，所以空间复杂度为O(|V|)
    
    * 时间复杂度：
      
          1. 邻接表：遍历过程的主要操作是对顶点遍历它的邻接点，由于通过访问边表来查找邻接点，所以时间复杂度为O(|E|),访问顶点时间为O(|V|),所以总的时间复杂度为O(|V|+|E|)
          
          2. 邻接矩阵：查找每个顶点的邻接点时间复杂度为O(|V|),对每个顶点都进行查找，所以总的时间复杂度为O(|V|2)    
      
      
      ​    
      ​    
      ​    
      
      ​        

#### 广度优先遍历

* 广度优先搜索(BFS:Breadth-First-Search)：广度优先搜索类似于树的层序遍历算法
    * 空间复杂度：**BFS需要借助一个队列**，n个顶点均需要入队一次，所以最坏情况下n个顶点在队列，那么则需要O(|V|)的空间复杂度。    
    * 时间复杂度：
      1. 邻接表：每个顶点入队一次，时间复杂度为O(|V|),对于每个顶点，搜索它的邻接点，就需要访问这个顶点的所有边，所以时间复杂度为O(|E|)。所以总的时间复杂度为O(|V|+|E|)
      2. 邻接矩阵：每个顶点入队一次，时间复杂度为O(|V|),对于每个顶点，搜索它的邻接点，需要遍历一遍矩阵的一行，所以时间复杂度为O(|V|),所以总的时间复杂度为O(|V|2)



### 图的应用

![image-20200720090752462](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200720090752462.png)



#### 最小生成树

#### 1、Prim算法

**与Dijkstra区别：Dijkstra算法是更新到起始点的距离；Prim是更新到集合S的距离 **

- **思路：**
  1. **找集合之外距离最近的点**
  2. **标记这个点(并加入集合)**
  3. **用这个点 $t$ 更新其他点到集合的距离**

* 双重循环，外层循环次数为n-1，内层并列的两个循环次数都是n。故普利姆算法时间复杂度为$O(n ^2)$
而且时间复杂度只和n有关，所以适合稠密图

![prim1.jpg](https://cdn.acwing.com/media/article/image/2020/04/29/9016_316fc95089-prim1.jpg)



```c++
#include<iostream>
#include<cstring>
#include<algorithm>

using namespace std;

const int N = 510, INF = 0x3f3f3f3f;

int n, m;
int g[N][N];
int dist[N];
bool st[N];

int prim()
{
    int res = 0;

    memset(dist, 0x3f, sizeof dist);

    for (int i = 0; i < n ; i ++ )
    {
        int t = -1;
        // 1.找集合之外距离最近的点
        for (int j = 1; j <= n ; j ++ )
        {
            if (!st[j] && (t == -1 || dist[t] > dist[j]))
                t = j;
        }
        // 2. 标记这个点(并加入集合)
        st[t] = true;

        if (i && dist[t] == INF) return INF;  //如果不是第一个点还距离∞，说明图不连通
        if (i) res += dist[t];  // 不是第一个点，加入集合 

        // 3. 用t更新其他点到集合的距离
        for (int j = 1; j <= n ; j ++ )
            dist[j] = min(dist[j], g[t][j]);
    }

    return res;
}

int main()
{
    cin >> n >> m;

    memset(g, 0x3f, sizeof g);

    while (m -- )
    {
        int a, b, c;
        cin >> a >> b >> c;

        g[a][b] = g[b][a] = min(g[a][b], c);
    }

    int t = prim();

    if (t == INF) puts("impossible");
    else cout << t << endl;

    return 0;
}

```





#### 2、Kruskal算法

* **思路：$O(mlogm)$**
    1. **将图中边按照权值从小到大排列**
    2. **然后从最小的边开始枚举。如果该边并入不构成回路的话，将该边并入集合中（当前生成树）。直到所有的边都检测完为止。**
* 概要: 克鲁斯卡尔算法操作分为对边的权值排序部分和一个单重for循环，它们是并列关系，由于排序耗费时间大于单重循环，所以克鲁斯卡尔算法的主要时间耗费在排序上。排序和图中边的数量有关系，所以适合稀疏图

![kruskal.jpg](https://cdn.acwing.com/media/article/image/2020/04/29/9016_92fa9eb289-kruskal.jpg)



```c++
#include<iostream>
#include<algorithm>
#include<cstring>

using namespace std;

const int N = 100010, M = 200010, INF = 0x3f3f3f3f;

int n, m;
int p[N];

struct Edges{
    int a, b, w;

    bool operator< (const Edges &e) const 
    {
        return w < e.w;
    }
}edges[M];

int find(int x)
{
    if (p[x] != x) p[x] = find(p[x]);
    return p[x];
}

int kruskal()
{
    // 1. 对边权从小到大排序
    sort(edges, edges + m);

    for (int i = 1; i <= n; i ++ ) p[i] = i;  // 初始化并查集

    int res = 0, cnt = 0;  // cnt 用来统计边数
    // 2. 从小到大枚举每条边，边连上，长度加上，计数+1
    for (int i = 0; i < m ; i ++ ) 
    {
        int a = edges[i].a, b = edges[i].b, w = edges[i].w;

        a = find(a), b = find(b);

        if (a != b)
        {
            p[a] = b;
            res += w;
            cnt ++ ;
        }
    }

    if (cnt < n - 1) return INF;  // 连通图的边数 = 点数 - 1 
    else return res;
}

int main()
{
    cin >> n >> m;
    for (int i = 0; i < m ; i ++ )
    {
        int a, b, w;
        cin >> a >> b >> w;

        edges[i] = {a, b, w};
    }

    int t = kruskal();

    if (t == INF) puts("impossible");
    else cout << t << endl;

    return 0;
}
```





#### 最短路径

#### 1、Dijkstra算法

* **单源最短路：一个源点到其余顶点的最短路径**



![朴素dijstra.PNG](https://cdn.acwing.com/media/article/image/2020/04/25/9016_29bf5da886-%E6%9C%B4%E7%B4%A0dijstra.PNG)



```c++
#include<iostream>
#include<algorithm>
#include<cstdio>
#include<cstring>

using namespace std;

const int N = 510;

bool st[N];
int dist[N];
int g[N][N];
int n, m;

int dijstra()
{
    memset(dist, 0x3f, sizeof dist);

    dist[1] = 0;

    for (int i = 0; i < n; i ++ )
    {
        int t = -1;  // t用来求所有st[] == false的节点中，dist[]最小的节点编号。

        // 1. t = 不在s中的距离最近的点
        for (int j = 1; j <= n; j ++ )
        {
            if (!st[j] && (t == -1 || dist[j] < dist[t]))
                t = j;
        }
        // 2. 标记为true
        st[t] = true;    

        // 3. 用t更新来更新其他点到 起点 的距离
        for (int j = 1; j <= n; j ++ )
            dist[j] = min(dist[j], dist[t] + g[t][j]);

    }

    if (dist[n] == 0x3f3f3f3f) return -1;
    else return dist[n];

}

int main()
{
    scanf("%d%d", &n, &m);
    memset(g, 0x3f, sizeof g);

    while(m -- )
    {
        int a, b, c;
        scanf ("%d%d%d", &a, &b, &c);

        g[a][b] = min(g[a][b], c);
    }

    int t = dijstra();

    printf("%d\n", t);

    return 0;
}

```



#### 2、弗洛伊德

* **多源汇最短路：所有顶点到所有顶点的最短路径（询问从i->j的最短路）**
    * 算法思想：
递推产生一个n阶方阵序列A(−1)，A(0)，…，A(k)，…，A(n−1)
其中A(k)[i][j]表示从顶点vi到顶点vj的路径长度，k表示绕行第k个顶点的运算步骤。初始时，对于任意两个顶点vi和vj，若它们之间存在边，则以此边上的权值作为它们之间的最短路径长度；若它们之间不存在有向边，则以∞作为它们之间的最短路径长度。以后逐步尝试在原路径中加入顶点k(k=0，1，…，n-1)作为中间顶点。如果增加中间顶点后，得到的路径比原来的路径长度减少了，则以此新路径代替原路径
    * 非带权图
* 两点之间经过边数最少的路径
    * 带权图
* 两点之间经过的边上权值之和最小的路径

```c++
#include<iostream>
#include<algorithm>
#include<cstring>

using namespace std;

const int N = 210, INF = 0x3f3f3f3f;

int dist[N][N];
int n, m, q;  // q是询问次数：询问从i->j的最短路。(所以这是多元最短路问题！！！)

void floyd()
{
    for (int k = 1; k <= n; k ++ )
        for (int i = 1; i <= n; i ++ )
            for (int j = 1; j <= n; j ++ )
                dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j]);
}

int main()
{
    cin >> n >> m >> q;

    for (int i = 1; i <= n; i ++ )
        for (int j = 1; j <= n; j ++ )
            if (i == j) dist[i][j] = 0;
            else dist[i][j] = INF;

    while(m -- )
    {
        int a, b, c;
        cin >> a >> b>> c;

        dist[a][b] = min(dist[a][b], c);
    }

    floyd();

    while(q -- )
    {
        int i, j;
        cin >> i >> j;

        int t = dist[i][j];

        // 不能走到终点，但由于负数边权的存在，终点的距离可能被其他长度是正无穷的距离更新。
        // 跟 INF / 2比较可以处理这种情况。
        if (t > INF / 2) puts("impossible");
        else cout << t << endl;
    }


    return 0;

}

```





#### 拓扑排序

- 拓扑排序常用来确定一个依赖关系集中，事物发生的顺序。例如，在日常工作中，可能会将项目拆分成A、B、C、D四个子部分来完成，但A依赖于B和D，C依赖于D。为了计算这个项目进行的顺序，可对这个关系集进行拓扑排序，得出一个线性的序列，则排在前面的任务就是需要先完成的任务。

* AOV(Activity On Vertex)
  
* 如果我们把每个环节看成图中一个顶点，在这样一个有向图中，用顶点表示活动，用弧表示活动之间的优先关系，那么这样的有向图称为AOV网(Activity On Vertex)
  
* 拓扑排序就是对一个有向图构造拓扑序列的过程，构造会有两种结果：
  如果此图全部顶点都被输出了，说明它是不存在回路的AOV网；
  如果没有输出全部顶点，则说明这个图存在回路，不是AOV网。

* **拓扑排序算法：**
 从AOV网中**选择一个入度为0的顶点输出，然后删去此顶点，并删除以此顶点为弧尾的弧**。重复这个步骤<u>直到输出图中全部顶点，或者找不到入度为0的顶点为止。</u>

* **拓扑排序流程(bfs)：**

   1. **遍历所有点找到入度为0的点，把它们入队**

   2. **开始从入度为0的点 找：**

      1. **队头出队**
      2. **遍历队头的临边**
      3. **临边的入度 - 1** 

      4. **判断此时入度是否为0：为0说明它可以做新的起点，入队**

   3. **return tt == n - 1 (队尾下标是n-1，说明所有点都已经入队)**.

```c++
#include<iostream>
#include<algorithm>
#include<cstring>

using namespace std;

const int N = 100010;

int n, m;
int h[N], e[N], ne[N], idx;
int d[N];
int q[N];

void add(int a, int b)
{
    e[idx] = b, ne[idx] = h[a], h[a] = idx ++ ;
}

bool topsort()
{
    int hh = 0, tt = -1;

    for (int i = 1; i <= n; i ++ )
        if (d[i] == 0) //  等同于 if (!d[i])
            q[ ++ tt ] = i;

    while(hh <= tt)
    {
        int t = q[hh ++ ];

        for (int i = h[t]; i != -1; i = ne[i])
        {
            int j = e[i];  // 找到出边！
            d[j] -- ;
            if (d[j] == 0)
            {
                q[ ++ tt] = j;
            }

        }
    }

    return tt == n - 1;
}

int main()
{
    cin >> n >> m;

    memset(h, -1, sizeof h);

    while(m -- )
    {
        int a, b;
        cin >> a >> b;

        add(a, b);
        d[b] ++ ;
    }

    if (!topsort()) puts("-1");
    else
    {
        for (int i = 0; i < n; i ++ )
            cout << q[i] << ' ';
    }

    return 0;
}

```



* 关键路径
    * AOE(Activity On Edge):在一个表示工程的带权有向图中，用顶点表示事件，用有向边表示活动，用边上的权值表示活动的持续时间，这种有向图的边表示活动的网称为AOE网。





## 第六章：查找

### 查找的基本概念和顺序查找
* 查找定义：在数据集合中寻找满足某种条件的数据元素的过程称为查找
* 关键字：数据元素中某个可以以唯一标识该元素的数据项
* 平均查找长度（ASL：Average Search Length）:在查找的过程中，一次查找的长度是指需要比较的关键字次数，而平均查找长度则是所有查找过程中进行关键字的比较次数的平均值
* 顺序查找(线性查找)，主要用于在线性表中进行查找。从查找表的一端开始，顺序扫描查找表，依次将扫描到的关键字和待查找的值key进行比较。如果相等，则查找成功。如果扫描结束仍然没有发现相等的数据元素，则查找失败。
    * 1
    * 2
    * 3 
    * 4
    * 时间复杂度为O(n)
### 折半查找
* 算法思路：
    * 首先将给定值key与表中中间位置元素的关键字比较，若相等，则查找成功，返回该元素的存储位置；若不等，则所需查找的元素只能在中间元素以外的前半部分或后半部分中。然后在缩小的范围内继续进行同样的查找，如此重复直到找到为止，或者确定表中没有所需要查找的元素，则查找不成功，返回查找失败的信息。
* 折半查找分析
    * 折半查找判定树
        * 对于折半查找，查找的比较次数就是从根结点到该结点经历的结点数
        * 时间复杂度为O(logn)
        * 概要: 具有N个（N>0）结点的完全二叉树的高度为 [log2(N+1)] 或 [log2N] +1。

### 分块查找
* 分块查找又称为索引顺序查找
* 分块查找思想：
    * ①确定待查找值在哪个块（折半查找）

②在确定的块中查找待查找值（顺序查找）
* 分块查找分析
    * 由于分块查找实际是进行两次查找，所以整个算法的平均查找长度是两次查找的平均查找长度之和。
即ASL分块=ASL折半+ASL顺序
        *  
### 二叉排序树
* 二叉排序树(Binary Search Tree 也叫二叉搜索树)或者是一棵空树，或者是具有以下性质的二叉树
①若左子树不空，则左子树上所有结点的值均小于它的根结点的值。
②若右子树不空，则右子树上所有结点的值均大于它的根结点的值。
③它的左右子树也是一棵二叉排序树。
* 算法思想
    * 由于二叉排序树的特点(左子树<根结点<右子树),所以每次查找一个关键字，需要先和根结点进行比较：
如果这个关键字小于根结点的值，则再到这个根结点的左子树进行同样的比较操作一直进行下去直到找到该关键字，表示查找成功，或者是空指针，表示查找失败。
如果这个关键字大于根结点的值，则再到这个根结点的右子树进行同样的比较操作一直进行下去直到找到该关键字，表示查找成功，或者是空指针，表示查找失败。
        * 查找关键字代码
            * 1 
            * 2
        * 插入关键字代码
            * 1)空树：直接插入新结点返回成功
2)树不空：检查是否存在关键字重复的结点：
①存在：返回插入失败
②不存在：检查根结点的值和待插入关键字值的大小关系递归插入左右子树
            *  
        * 构造代码
            *  
        * 删除结点
            * ①删除的是叶子结点
                * 方法：直接删去该结点即可
            * ②删除的是仅有左子树或者右子树的结点
                * 方法：“子承父业”
            * ③删除的是左右子树都有的结点
                * 仿照②类型，先将一个孩子“继承父业”，另一个孩子“归顺”于这个孩子
方法：找到待删除结点的直接前驱或者直接后继结点，用该结点来替换待删除结点，再删除该结点。
* 二叉排序树分析
    * 查找时间复杂度是O(n)
* 概要: “左小右大”
### 平衡二叉树(AVL树)
* 平衡二叉树(AVL树)是特殊的二叉排序树，特殊的地方在于左右子树的高度之差绝对值不超过1，而且左右子树又是一棵平衡二叉树。
* 平衡因子
    * 定义结点左子树与右子树的高度差为该结点的平衡因子，则平衡二叉树结点的平衡因子的值只可能是−1、0或1。
* 平衡调整
    * 平衡二叉树的建立过程和二叉排序树的建立过程是相似的，都是从一棵空树开始陆续插入结点。不同的地方在于对于平衡二叉树的建立过程中，由于插入结点可能会破坏结点的平衡性，所以需要进行平衡调整。

        * LL调整(左孩子的左子树上插入结点导致)
            * 最小不平衡子树根结点的平衡因子为2>0
它的左孩子结点平衡因子为1>0
两个都大于0，所以直接右旋就可以调整
            * 概要: “正则右旋”
        * RR调整(右孩子的右子树上插入结点导致)
            *  最小不平衡子树根结点的平衡因子为-2<0
它的右孩子结点平衡因子为-1<0
两个都小于0，所以直接左旋就可以调整
            * 概要: “负则左旋”
        * LR调整(左孩子的右子树上插入结点导致)
        * RL调整(右孩子的左子树上插入结点导致)
        * 概要: 先局部转换为LL或RR，最后进行调整
* 分析
    * 含有n个结点平衡二叉树的最大深度为O(log2n)，因此，平衡二叉树的平均查找长度为O(log2n) 
### B树和B+树
* 2-3树
    * 2-3树是一种多路查找树：2和3的意思就是2-3树包含两种结点
        * 1)2结点包含一个元素和两个孩子(或者没有孩子)。
    ①左子树包含的元素小于该结点的元素值，右子树包含的元素大于该结点的元素值
    ②2结点要不有两个孩子，要不就没有孩子，不允许有一个孩子
        * 2)3结点包含一大一小两个元素和三个孩子(或者没有孩子)。(两个元素按大小顺序排列好)
    ①左子树包含的元素小于该结点较小的元素值，右子树包含的元素大于该结点较大的元素值，中间子树包含的元素介于这两个元素值之间。
    ②3结点要不有三个孩子，要不就没有孩子，不允许有一个或两个孩子
        * 3)2-3树所有叶子结点都在同一层次
* 2-3-4树
    * 2-3-4树也是一种多路查找树：2和3和4的意思就是2-3-4树包含三种结点
        * 1)2结点包含一个元素和两个孩子(或者没有孩子)。
    ①左子树包含的元素小于该结点的元素值，右子树包含的元素大于该结点的元素值
    ②2结点要不有两个孩子，要不就没有孩子，不允许有一个孩子
        * 2)3结点包含一大一小两个元素和三个孩子(或者没有孩子)。
    ①左子树包含的元素小于该结点较小的元素值，右子树包含的元素大于该结点较大的元素值，中间子树包含的元素介于这两个元素值之间。
    ②3结点要不有三个孩子，要不就没有孩子，不允许有一个或两个孩子
        * 3)4结点包含小中大三个元素和四个孩子(或者没有孩子)。
    ①左子树包含的元素小于该结点最小的元素值，第二个子树包含大于最小的元素值小于中间元素值的元素，第三个子树包含大于中间元素值小于最大元素值的元素，右子树包含的元素大于该结点最大的元素值。   
    ②4结点要不有四个孩子，要不就没有孩子，不允许有一个或两个或三个孩子
        * 4)2-3-4树所有叶子结点都在同一层次
* B树
    * B树也是一种平衡的多路查找树，2-3树和2-3-4树都是B树的特例，我们把树中结点最大的孩子数目称为B树的阶。通常记为m。
一棵m阶B树或为空树，或为满足如下特性的m叉树：
        * 1）树中每个结点至多有m棵子树。（即至多含有m-1个关键字) ("两棵子树指针夹着一个关键字")
        * 2）若根结点不是终端结点，则至少有两棵子树。(至少一个关键字)
        * 3）除根结点外的所有非叶结点至少有 ⌈m/2⌉棵子树。（即至少含有⌈m/2⌉-1个关键字）
        * 4）所有非叶结点的结构如下：
        * 5）所有的叶子结点出现在同一层次上，不带信息。(就像是折半查找判断树中查找失败的结点)
    * 1.B树的查找操作
        * 查找过程：①先让待查找关键字key和结点的中的关键字比较，如果等于其中某个关键字，则查找成功。
                  ②如果和所有关键字都不相等，则看key处在哪个范围内，然后去对应的指针所指向的子树中查找。
                      Eg:如果Key比第一个关键字K1还小，则去P0指针所指向的子树中查找，如果比最后一个关键字Kn还大，则去Pn指针所指向的子树中查找。

    * 2.B树的插入操作
        * 分裂的方法：取这个关键字数组中的中间关键字(⌈n/2⌉)作为新的结点，然后其他关键字形成两个结点作为新结点的左右孩子。
    * 3.B树的删除操作
        * B树中的删除操作与插入操作类似，但要稍微复杂些，要使得删除后的结点中的关键字个数≥⌈m/2⌉-1 ，因此将涉及结点的“合并”问题。由于删除的关键字位置不同，可以分为关键字在终端结点和不在终端结点上两种情况。
            * 1）如果删除的关键字在终端结点上（最底层非叶子结点）：
      ①结点内关键字数量大于⌈m/2⌉-1 ，这时删除这个关键字不会破坏B树的定义要求。所以直接删除。
      ②结点内关键字数量等于⌈m/2⌉-1 ，并且其左右兄弟结点中存在关键字数量大于⌈m/2⌉-1 的结点，则去兄弟阶段中借关键字。
      ③结点内关键字数量等于⌈m/2⌉-1 ，并且其左右兄弟结点中不存在关键字数量大于⌈m/2⌉-1 的结点，则需要进行结点合并。

            * 2）如果删除的关键字不在终端结点上（最底层非叶子结点）：需要先转换成在终端结点上，再按照在终端结点     上的情况来分别考虑对应的方法。
                * 相邻关键字：对于不在终端结点上的关键字,它的相邻关键字是其左子树中值最大的关键字或者右子树中值最小的关键字。
                * 第一种情况：存在关键字数量大于⌈m/2⌉-1 的左子树或者右子树，在对应子树上找到该关键字的相邻关键字，然后将相邻关键字替换待删除的关键字。
                * 第二种情况：左右子树的关键字数量均等于⌈m/2⌉-1 ，则将这两个左右子树结点合并，然后删除待删除关键字。
* B+树
    * B+树是常用于数据库和操作系统的文件系统中的一种用于查找的数据结构
    * m阶的B+树与m阶的B树的主要差异在于：
1）在B+树中，具有n个关键字的结点只含有n棵子树，即每个关键字对应一棵子树；而在B树中，具有n个关键字的结点含有(n+1)棵子树。
2）在B+树中，每个结点（非根内部结点）关键字个数n的范围是 ⌈m/2⌉≤n≤m（根结点1≤n≤m），在B树中，每个结点（非根内部结点）关键字个数n的范围是⌈m/2⌉ -1≤n≤m-1（根结点：1≤n≤m-1）。
3）在B+树中，叶结点包含信息，所有非叶结点仅起到索引作用，非叶结点中的每个索引项只含有对应子树的最大关键字和指向该子树的指针，不含有该关键字对应记录的存储地址。
4）在B+树中，叶结点包含了全部关键字，即在非叶结点中出现的关键字也会出现在叶结点中；而在B树中，叶结点包含的关键字和其他结点包含的关键字是不重复的。
### 散列表
* 散列表：根据给定的关键字来计算出关键字在表中的地址的数据结构。也就是说，<u>散列表建立了关键字和存储地址之间的一种直接映射关系。</u>
* 散列函数：一个把查找表中的关键字映射成该关键字对应的地址的函数，记为Hash(key)=Addr。
* <u>散列函数可能会把两个或两个以上的不同关键字映射到同一地址</u>，称这种情况为“冲突”，这些发生碰撞的不同关键字称为同义词。
* 构造散列函数的tips：
    * 1）散列函数的定义域必须包含全部需要存储的关键字，而值域的范围则依赖于散列表的大小或地址范围。
    * 2）散列函数计算出来的地址应该能等概率、均匀地分布在整个地址空间，从而减少冲突的发生。
    * 3）散列函数应尽量简单，能够在较短的时间内就计算出任一关键字对应的散列地址。

1.常用Hash函数的构造方法：

* 1.开放定址法：直接取关键字的某个线性函数值为散列地址，散列函数为H(key)=a×key+b。式中，a和b是常数。这种方法计算最简单，并且不会产生冲突
* 2.除留余数法：假定散列表表长为m，取一个不大于m但最接近或等于m的质数p，利用以下公式把关键字转换成散列地址。散列函数为H(key)=key % p
除留余数法的关键是选好p，使得每一个关键字通过该函数转换后等概率地映射到散列空间上的任一地址，从而尽可能减少冲突的可能性
* 3.数字分析法：设关键字是r进制数（如十进制数），而r个数码在各位上出现的频率不一定相同，可能在某些位上分布均匀些，每种数码出现的机会均等；而在某些位上分布不均匀，只有某几种数码经常出现，则应选取数码分布较为均匀的若干位作为散列地址。这种方法适合于已知的关键字集合
* 4.平方取中法：顾名思义，取关键字的平方值的中间几位作为散列地址。具体取多少位要看实际情况而定。这种方法得到的散列地址与关键字的每一位都有关系，使得散列地址分布比较均匀。
* 5.折叠法：将关键字分割成位数相同的几部分（最后一部分的位数可以短一些），然后取这几部分的叠加和作为散列地址，这种方法称为折叠法。关键字位数很多，而且关键字中每一位上数字分布大致均匀时，可以采用折叠法得到散列地址。

2.常用Hash函数的冲突处理办法：

* 1.开放定址法：将产生冲突的Hash地址作为自变量，通过某种冲突解决函数得到一个新的空闲的Hash地址。
  
    * 1）线性探测法：冲突发生时，顺序查看表中下一个单元（当探测到表尾地址m-1时，下一个探测地址是表首地址0），直到找出一个空闲单元或查遍全表。

      容易产生**堆积问题**。因为连续出现若干同义词后，设第一个同义词占用单元d，这些连续的同义词将占用哈希表的d，d+1，d+2等单元，此后，任何d+1，d+2等单元上的哈希映射都会因为前面的同义词堆积而产生冲突。
    
    * 2）平方探测法：设发生冲突的地址为d,平方探测法得到的新的地址序列为$(d+1)^2$，$(d-1)^2$，$(d+2)^2$，$(d-2)^2$......
      平方探测法是一种较好的处理冲突的方法，**可以避免出现“堆积”问题，它的缺点是不能探测到散列表上的所有单元，但至少能探测到一半单元。**
    
    * 3）再散列法：又称为双散列法。需要使用两个散列函数，当通过第一个散列函数H(Key)得到的地址发生冲突时，则利用第二个散列函数Hash2(Key)计算该关键字的地址增量。
    
    * 4）伪随机序列法：当发生地址冲突时，地址增量为伪随机数序列，称为伪随机序列法。
* 2.拉链法：对于不同的关键字可能会通过散列函数映射到同一地址，为了避免非同义词发生冲突，可以把所有的同义词存储在一个线性链表中，这个线性链表由其散列地址唯一标识。拉链法适用于经常进行插入和删除的情况。
* 3.散列表的查找过程：类似于构造散列表，给定一个关键字Key。
  先根据散列函数计算出其散列地址。然后检查散列地址位置有没有关键字。
     1)如果没有，表明该关键字不存在，返回查找失败。
     2)如果有，则检查该记录是否等于关键字。
             ①如果等于关键字，返回查找成功。
             ②如果不等于，则按照给定的冲突处理办法来计算下一个散列地址，再用该地址去执行上述过程。
* 4.散列表的查找性能：和装填因子有关。
    *  
    * α越大，表示装填的记录越“满”，发生冲突的可能性就越大，反之发生冲突的可能性越小





## 第七章：排序

### 排序的基本知识
* 定义：排序就是将原本无序的序列重新排列成有序的序列。
* 排序的稳定性
    * 如果待排序表中有两个元素Ri、Rj，其对应的关键字keyi=keyj，且在排序前Ri在Rj前面，如果使用某一排序算法排序后，Ri仍然在Rj的前面，则称这个排序算法是稳定的，否则称排序算法是不稳定的。

- 算法复杂度
  - 时间复杂度：<u>执行算法所需的计算工作量；基本操作的执行次数</u>
  - 空间复杂度：<u>执行算法所需的内存空间</u>



### 排序总结

![](C:\Users\HP\AppData\Roaming\Typora\typora-user-images\image-20200714203212921.png)



|   算法种类   | 最好时间复杂度 | 最坏时间复杂度 | 平均时间复杂度 | 空间复杂度 | 是否稳定 |
| :----------: | :------------: | :------------: | :------------: | :--------: | :------: |
| 直接插入排序 |      O(n)      |     O(n^2)     |     O(n^2)     |    O(1)    |   稳定   |
| 折半插入排序 |    O(logn)     |     O(n^2)     |     O(n^2)     |    O(1)    |   稳定   |
|   希尔排序   |                |                |   O(n^{1.3})   |    O(1)    |  不稳定  |
|   冒泡排序   |      O(n)      |     O(n^2)     |     O(n^2)     |    O(1)    |   稳定   |
|   快速排序   |    O(nlogn)    |     O(n^2)     |    O(nlogn)    |  O(logn)   |  不稳定  |
| 简单选择排序 |    O(n^2 )     |     O(n^2)     |     O(n^2)     |    O(1)    |  不稳定  |
|    堆排序    |    O(nlogn)    |    O(nlogn)    |    O(nlogn)    |   O(1 )    |  不稳定  |
|   归并排序   |    O(nlogn)    |    O(nlogn)    |    O(nlogn)    |   O( n)    |  不稳定  |
|   基数排序   |                |                |  O(d(n+r_d))   |   O(r_d)   |  不稳定  |



### 一、插入类排序

#### 1、直接插入排序

* 直接插入排序：首先以一个元素为有序的序列，然后将后面的元素依次插入到有序的序列中合适的位置直到所有元素都插入有序序列。
* 时间复杂度
  * 最好：序列是有序的，$O(n)$
  * 最差：倒序的，$O(n^{2})$               $n * (n-1) /2$
  * 平均：$O(n^{2})$   
* 空间复杂度：$O(1)$
* 直接插入排序是稳定性是稳定的。

```c++
void insertSort(int q[])
{
    for (int i = 1; i < n ; i ++ )  // 数组下标从0开始
    {
        int tmp = q[i], j = i - 1;
        while(j >= 0 && q[j] > tmp)
        {
            q[j + 1] = q[j];
            j -- ;
        }
        q[j + 1] = tmp;
    }   
}
```



#### 2、==折半插入排序==

* 折半插入排序将比较和移动这=两个操作分离出来，也就是先利用折半查找（二分查找）找到插入的位置，然后一次性移动元素，再直接插入该元素。（二分查找+直接插入）

* 复杂度

  | 最好时间复杂度 | 最差时间复杂度 | 平均时间复杂度 | 空间复杂度 | 是否稳定 |
  | :------------: | :------------: | :------------: | :--------: | :------: |
  |  $O(nlog_n)$   |    $O(n^2)$    |   $O(n^2 )$    |  $O( 1) $  |   稳定   |

  

```c++

```



#### 3、希尔排序

* 希尔排序的基本思想：<u>希尔排序本质上还是插入排序，只不过是把待排序序列分成几个子序列，再分别对这几个子序列进行直接插入排序。</u>
    * 先以增量5来分割序列，也就是下标为0,5,10,15...的关键字分成一组，下标为1,6,11,16..分成一组,然后对这些组分别进行<u>直接插入排序</u>，这就完成了一轮希尔排序。
    * 缩小增量(d1=n/2，di+1= [di/2]，比如10个数据序列，第一次增量d1=10/2=5,第二次增量d2= [d1/2]= [5/2]=2,并且最后一个增量等于1),所以第二轮以增量为2进行类似的排序过程。
    * 接下来的第三轮，第四轮...都是类似的过程，直到最后一轮以增量为1。此时就是前面所说的直接插入排序。



* 复杂度：希尔排序的时间复杂度约为   $O(n^{1.3})$    在最坏情况下希尔排序的时间复杂度为O(n^2)

    | 最好时间复杂度 | 最差时间复杂度 | 平均时间复杂度 | 空间复杂度 | 是否稳定 |
    | :------------: | :------------: | :------------: | :--------: | :------: |
    |                |    $O(n^2)$    |   $O(n^1.3)$   |  $O( 1) $  |  不稳定  |

* 稳定性：不稳定，由于不同的增量可能就会把相等的关键字划分到两个直接插入排序中进行排序， 可能就会造成相对顺序变化。

```

```







### 二、交换类排序
#### 1、冒泡排序

* 假设待排序表长为n，从后往前（或从前往后）两两比较相邻元素的值，若为逆序（即A[i-1]>A[i]），则交换它们，直到序列比较完。我们称它为一趟冒泡，结果将最小的元素交换到待排序列的第一个位置。下一趟冒泡时，前一趟确定的最小元素不再参与比较，待排序列减少一个元素，每趟冒泡的结果把序列中的最小元素放到了序列的最终位置，……，这样最多做 $n-1$ 趟冒泡就能把所有元素排好序。

* 复杂度

  | 最好时间复杂度 | 最差时间复杂度 | 平均时间复杂度 | 空间复杂度 | 是否稳定 |
  | :------------: | :------------: | :------------: | :--------: | :------: |
  |     $O(n)$     |    $O(n^2)$    |   $O(n^2 )$    |  $O( 1) $  |   稳定   |

* 稳定性：当两个关键字相等，if判断条件不成立，所以不会发生数据移动。所以是稳定的

```c++
// 数组下标从1开始
void bubbleSort(int q[])
{
    
    for (int i = n - 1; i >= 1; i -- )  // n
    {
        bool flag = false;     // flag用来标记本堂排序是否发生了改变
        for (int j = 1; j <= i; j ++ ) 
        {
            if (q[j] > q[j + 1])
            {
                swap(q[j], q[j + 1]);
                flag = true;
            }
        }
        if (flag = false) return ;  // 
    }
}
```



#### 2、快速排序

* 快速排序是一种基于**分治法**的排序方法。
每一趟快排选择序列中任一个元素作为枢轴(通常选第一个元素)，将序列中比枢轴小的元素都移到枢轴前边，比枢轴大的元素都移到枢轴后边。
  
* 复杂度

  | 最好时间复杂度 | 最差时间复杂度 | 平均时间复杂度 | 空间复杂度 | 是否稳定 |
  | :------------: | :------------: | :------------: | :--------: | :------: |
  |  $O(nlog_n)$   |    $O(n^2)$    |   $O(nlogn)$   | $O(logn)$  |  不稳定  |

* 时间复杂度：
  最好情况下时间复杂度为$O(nlogn)$，待排序序列越无序，算法效率越高。
  最坏情况下时间复杂度为$O(n^2)$，待排序序列越有序，算法效率越低。

* 空间复杂度：
  由于快速排序是递归的，需要借助一个**递归工作栈**来保存每一层递归调用的必要信息，其容量应与递归调用的最大深度一致。
  最好情况下为 ⌈log2(n+1)⌉(每次partition都很均匀)递归树的深度O(logn)
  最坏情况下，因为要进行n-1次递归调用，所以栈的深度为O(n)；

* 稳定性：快速排序是不稳定的，是因为存在交换关键字。





### 三、选择类排序
#### 1、简单选择排序

* 从头到尾扫描序列，找出最小的关键字，

* 复杂度

  | 最好时间复杂度 | 最差时间复杂度 | 平均时间复杂度 | 空间复杂度 | 是否稳定 |
  | :------------: | :------------: | :------------: | :--------: | :------: |
  |    $O(n^2)$    |    $O(n^2)$    |    $O(n^2)$    |   $O(1)$   |  不稳定  |

* 时间复杂度：
关键操作在于交换元素操作，整个算法由双重循环组成，外层循环从0到n-2一共n-2+1=n-1次，
对于第i层外层循环，内层循环执行n-1-(i+1)+1=n-i-1次。
                  当i=0,内层循环执行n-1次，当i=n-2,内层循环执行1次，所以是一个等差数列求和,一共为(1+n-1)(n-1)/2=n(n-1)/2 ,所以时间复杂度为O(n^2)
  
* 稳定性：不稳定   原因就在于交换部分会打破相对顺序

```c++
void select_sort(int q[])
{
    for (int i = 0; i < n - 1; i ++ )
    { 
        // 1.记最小关键字下标
        int pos = i;
        for (int j = i + 1; j < n; j ++ )
        {
            if (q[pos] > q[j]) pos = j;
        }
        
        // 2.交换
        if (pos != i) swap(q[pos], q[i]);
    }
}
```



#### 2、堆排序

* 什么是堆？
    * 堆是一棵完全二叉树，而且满足任何一个非叶结点的值都不大于(或不小于)其左右孩子结点的值。
        * 如果是每个结点的值都不小于它的左右孩子结点的值，则称为大顶堆。
        * 如果是每个结点的值都不大于它的左右孩子结点的值，则称为小顶堆。
* 什么是堆排序？
    * 我们知道对于一个堆来说，它的根结点是整个堆中所有结点的值的最大值(大顶堆)或者最小值(小顶堆)。所以堆排序的思想就是每次将无序序列调节成一个堆，然后从堆中选择堆顶元素的值，这个值加入有序序列，无序序列减少一个，再反复调节无序序列，直到所有关键字都加入到有序序列。
    * 时间复杂度：
      堆排序的总时间可以分为①建堆部分+②n-1次向下调整堆
    
     堆排序的时间复杂度为O(n)+O(nlog2n)=O(nlog2n)

    * 堆排序不稳定









### 四、归并排序

- **归并排序是分治的思想。先将整个序列分为两半，对每一半分别进行排序，得到两个有序序列，再将两个序列归并成一个序列即可。**

* 假定待排序表含有n个记录，则可以看成是n个有序的子表，每个子表长度为1，然后两两归并，得到 ⌈n/2⌉个长度为2或1的有序表；再两两归并，……如此重复，直到合并成一个长度为n的有序表为止，这种排序方法称为2-路归并排序。

* 例如：49 38 65 97 76 13 27
    * ①首先将整个序列的每个关键字看成一个单独的有序的子序列
    * ②两两归并，49和38归并成{38 49} ，65和97归并成{65 97}，76和13归并成{13 76}，27没有归并对象
    * ③两两归并，{38 49}和{65 97}归并成{38 49 65 97}，{13,76}和27归并成{13 27 76}
    * ④两两归并，{38 49 65 97}和{13 27 76}归并成{13 27 38 49 65 76 97}
    
* 复杂度

    | 最好时间复杂度 | 最差时间复杂度 | 平均时间复杂度 | 空间复杂度 | 是否稳定 |
    | :------------: | :------------: | :------------: | :--------: | :------: |
    |  $O(nlog n)$   |   $O(nlogn)$   |   $O(nlogn)$   |   $O(n)$   |   稳定   |

* 空间复杂度:因为需要将这个待排序序列转存到一个数组，所以需要额外开辟大小为n的存储空间，即空间复杂度为O(n)

* 稳定性：稳定



```c++
void merge_sort(int q[], int l, int r)
{
    if (l >= r) return ;
    
    int mid = l + r >> 1, i = l, j = mid + 1;
    
    merge_sort(q, l, mid), merge_sort(q, mid + 1,r);
    
    int k = 0;
    while(i <= mid && j <= r)
    {
        if (q[i] <= q[j]) tmp[k ++ ] = q[i ++ ];
        else tmp[k ++ ] = q[j ++ ];
    }
 
    while (i <= mid) tmp[k ++ ] = q[i ++ ];
    while (j <= r) tmp[k ++ ] = q[j ++ ];
    
    for (i = l, j = 0; i <= r; i ++ , j ++ ) q[i] = tmp[j];
}
```

![img](https://img-blog.csdnimg.cn/20190413205323408.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI1ODAwMzEx,size_16,color_FFFFFF,t_70)



![img](https://img-blog.csdnimg.cn/20190414183927348.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI1ODAwMzEx,size_16,color_FFFFFF,t_70)



可以发现，**归并排序的处理过程是由下到上的**，先处理子问题，然后再合并。而**快排正好相反，它的处理过程是由上到下的**，先分区，然后再处理子问题。**归并排序虽然是稳定的、时间复杂度为 O(nlogn) 的排序算法，但是它是非原地排序算法**。我们前面讲过，归并之所以是非原地排序算法，主要原因是**合并函数无法在原地执行**。**快速排序通过设计**巧妙的原地分区函数，**可以实现原地排序。**







### 五、基数排序
* 基数排序(也叫桶排序)是一种很特别的排序方法，它不是基于比较进行排序的，而是采用多关键字排序思想（即基于关键字各位的大小进行排序的），借助“分配”和“收集”两种操作对单逻辑关键字进行排序。基数排序又分为最高位优先（MSD）排序和最低位优先（LSD）排序。
* 例子：53, 3, 542, 748, 14, 214, 154, 63, 616
    * 补充位数：053, 003, 542, 748, 014, 214, 154, 063, 616
    * 桶实际是一个队列，先进先出(从桶的上面进，下面出)
    * 关键字数量为n,关键字的位数为d,比如748 d=3，r为关键字的基的个数，就是组成关键字的数据的种类，比如十进制数字一共有0至9一共10个数字，即r=10
* 空间复杂度：需要开辟关键字基的个数个队列，所以空间复杂度为O(r)
* 时间复杂度：需要进行关键字位数d次"分配"和"收集"，一次"分配"需要将n个关键字放进各个队列中，一次"收集"需要将r个桶都收集一遍。所以一次"分配"和一次"收集"时间复杂度为O(n+r)。d次就需要O(d(n+r))的时间复杂度。
* 稳定性：由于是队列，先进先出的性质，所以在分配的时候是按照先后顺序分配，也就是稳定的，所以收集的时候也是保持稳定的。即基数排序是稳定的排序算法。





### 外部排序
* 
* 如何得到初始的归并段
    * 置换选择排序：解决排序段放入内存的问题
* 如何减少多个归并段的归并次数
    * 最佳归并树：最少的归并次数（I/O次数）
* 如何每次m路归并快速得到最小的关键字
    * 败者树：减少比较次数
* 概要: 内存容量无法容纳大量数据



#### 







## 二叉树与树与森林

### 树与二叉树
* 如何将一棵树转化成二叉树？
    * 树的孩子兄弟表示法与二叉树的二叉链表表示法都是用到两个指针
        * 将孩子兄弟表示法理解成二叉链表
    * 树转换成二叉树的手动模拟方法：
        * ①将同一结点的各个孩子用线串连起来
        * ②将每个结点的子树分支，从左往右，除了第一个以外全部删除
        * 概要: 例子
* 如何将一棵二叉树转化成树？
    * 二叉树转换成树的手动模拟方法：
        * ①将二叉树从上到下分层，并调节成水平方向。
(分层方法：每遇到左孩子则为一层)
        * ②找到每一层的双亲结点，方法为它的上一层相连的那个结点就是双亲结点。
例如bcd这一层，与它相连的上一层结点即为a,所以bcd这三个结点的双亲结点都是a.
        * ③将每一层结点和其双亲结点相连，同时删除该双亲结点各个孩子结点之间的联系。
        * 概要: 例子
### 森林与二叉树
* 森林：森林是m（m≥0）棵互不相交的树的集合
* 如何将森林转换成二叉树？
    * 森林转换成树的手动模拟方法：
        * ①将森林中每棵树都转换成二叉树
        * ②将第二棵树作为第一棵树的根结点的右子树，将第三棵树作为第二棵树的根结点的右子树..依次类推
        * 概要: 例子
* 如何将二叉树转换成森林？
    * 二叉树转换成森林的手动模拟方法：
        * 反复断开二叉树根结点的右孩子的右子树指针，直到不存在根结点有右孩子的二叉树为止。
        * 概要: 例子
### 树与森林的遍历
* 先序：先访问根结点，再访问根结点的每棵子树。           访问子树也是按照先序的要求
* 后序：先访问根结点的每棵子树，再访问根结点。           访问子树也是按照先序的要求
* 树的先序遍历等于它对应二叉树的先序遍历，后序遍历等于它对应的二叉树的中序遍历
* 概要: 例子

![picture](https://github.com/SSHeRun/CS-Xmind-Note/blob/master/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png)









## 算法

### 求质数

#### 1、质数的判定——试除法 $O(sqrt(n))$

> d | n；那么 $\frac{n}{d}$ | n  
>
> 例：n = 12，2， 6；3，4； n的约数是成对出现的，所以可以只枚举每一对较小的那个

```c++
bool is_prime(int n)
{
    if (n < 2) return false;
    for(int i = 2; i <= n / i; i ++ )
    {
        if (n % i == 0) return false;
    }
    return true;
}
```



#### 2、分解质因数——试除法







































